{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81883de1-5183-4d3f-be1a-2c9361324b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "from myvars import to_billions_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07525fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 200 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de78e7d",
   "metadata": {},
   "source": [
    "# Create data tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4731fd0",
   "metadata": {},
   "source": [
    "## Companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163dade",
   "metadata": {},
   "source": [
    "- A table for all unique companies\n",
    "    - cik, symbol, name, sector, subsector, founded, etc\n",
    "- A table for all the periods a company has been on the index.\n",
    "    - cik, symbol, start date, end date, flag_current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f4bc4",
   "metadata": {},
   "source": [
    "#### Table for unique companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b89e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import companies csv\n",
    "current_companies = pd.read_csv('../data/raw/companies_wiki.csv').drop(columns='SEC filings')\n",
    "current_companies.columns = ['symbol', 'name', 'sector', 'subSector', 'hQ', 'dateFirstAdded', 'cik', 'founded']\n",
    "# import historical companies csv\n",
    "historical_v1 = pd.read_csv('../data/raw/historical_companies_wiki.csv')\n",
    "# import wikipedia historical companies csv\n",
    "spts = pd.read_csv('../data/raw/historical_companies_TradingEvolved.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801fe6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tickers</th>\n",
       "      <th>tickers_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-01-02</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "      <td>[AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996-01-03</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "      <td>[AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996-01-04</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "      <td>[AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996-01-10</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "      <td>[AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-01-11</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "      <td>[AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                            tickers  \\\n",
       "0  1996-01-02  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...   \n",
       "1  1996-01-03  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...   \n",
       "2  1996-01-04  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...   \n",
       "3  1996-01-10  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...   \n",
       "4  1996-01-11  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...   \n",
       "\n",
       "                                    tickers_filtered  \n",
       "0  [AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...  \n",
       "1  [AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...  \n",
       "2  [AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...  \n",
       "3  [AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...  \n",
       "4  [AAL, AAMRQ, AAPL, ABI, ABS, ABT, ABX, ACKH, A...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique occurences of anything that is in tickers\n",
    "# get the items on the list if there is no '-', if there is, get the first item (the ticker)\n",
    "spts['tickers_filtered'] = spts.tickers.str.split(',')\n",
    "spts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb622b",
   "metadata": {},
   "source": [
    "Get all unique constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa69fc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = set()\n",
    "spts.tickers_filtered.apply(results.update)\n",
    "companies = pd.DataFrame(data = results, columns=['symbol'])\n",
    "companies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3dff01",
   "metadata": {},
   "source": [
    "Add values from current companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af828914",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_companies['currentConstituent'] = True\n",
    "companies = companies.merge(current_companies, how='left')\n",
    "companies = companies.drop(columns=['dateFirstAdded'])\n",
    "companies.currentConstituent = companies.currentConstituent.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d68712",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciks = pd.read_csv('../data/raw/CIK.csv', index_col = 0)\n",
    "ciks.columns = ['cik_sec_list', 'symbol', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "739e101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = companies.merge(ciks, how='left')\n",
    "companies.name = companies.name.fillna(companies.title)\n",
    "companies.cik = companies.cik.fillna(companies.cik_sec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32176f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.to_csv('../data/preSQL/companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ef7c7",
   "metadata": {},
   "source": [
    "#### Table for historical constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a19ee1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_stays = pd.DataFrame(columns=['symbol', 'added', 'removed'])\n",
    "# iterate over the list of tickers for every day and\n",
    "previous_set=set()\n",
    "for date, list_tickers in spts.set_index('date').tickers_filtered.items():\n",
    "    # for the first iteration there is no previous set\n",
    "    new_set = set(list_tickers)\n",
    "    # check which values from the list of values was not in the previous date\n",
    "    diff_new = new_set-previous_set\n",
    "    # for each value in diff_new\n",
    "    for diff_ticker in diff_new:\n",
    "        if diff_ticker in new_set:\n",
    "            # the ticker has been added\n",
    "            new_row_index = 0 if len(sp500_stays) == 0 else sp500_stays.index.max()+1\n",
    "            new_row_data={\n",
    "                'symbol': diff_ticker,\n",
    "                'added': date,\n",
    "                'removed': 'not_yet_removed',\n",
    "                }\n",
    "            new_row = pd.DataFrame(data = new_row_data, index=[new_row_index])\n",
    "            sp500_stays = pd.concat([sp500_stays, new_row], axis=0)\n",
    "    diff_old = previous_set-new_set\n",
    "    for diff_ticker in diff_old:\n",
    "        if diff_ticker in previous_set:\n",
    "            # the ticker has been removed\n",
    "            # get the index of the last occurence of the ticker in the dataframe\n",
    "            mask = sp500_stays.symbol == diff_ticker\n",
    "            idx = sp500_stays[mask].index.max()\n",
    "            # update that index with the date removed\n",
    "            sp500_stays.loc[idx, 'removed'] = date\n",
    "    # this iteration ends, the new set becomes obsolete\n",
    "    previous_set = new_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d40f2f",
   "metadata": {},
   "source": [
    "to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e872e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_stays.to_csv('../data/clean/sp500_movements.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c0793",
   "metadata": {},
   "source": [
    "#### Aditional Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27657b",
   "metadata": {},
   "source": [
    "## SEC submissions\n",
    "Submissions from SEC\n",
    "- 10-KA/405A and 10QA are text amendments which contain no financial information. <a href=\"https://www.sec.gov/Archives/edgar/data/320193/0001047469-98-001822.txt\">example</a>\n",
    "- NT 10-Q and NT 10-K are notifications about delay in statements\n",
    "- 10KT and 10QT dennote transition in companies which alter fiscal years. Usually after merger of acquisitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions=pd.read_csv('.././data/raw/submissions.csv')\n",
    "sub_cols = [\n",
    "    'filingDate',\n",
    "    'reportDate',\n",
    "    'symbol',\n",
    "    'cik',\n",
    "    'form',\n",
    "    ]\n",
    "sec = submissions.loc[:,sub_cols]\n",
    "mask = sec.form.isin(['10-K', '10-Q', '10-K405', '10-KT', '10-QT'])\n",
    "sec = sec[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d328879",
   "metadata": {},
   "source": [
    "## FRED Series\n",
    "- Inflation\n",
    "- GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6871aa",
   "metadata": {},
   "source": [
    "### Inflation (CorePCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d8eda034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read inflation csv\n",
    "inflation = pd.read_csv('../data/raw/fred/corePCE.csv').convert_dtypes()\n",
    "# get last date\n",
    "last_date = inflation.date.idxmax()\n",
    "# get the coefficient of that date\n",
    "today_inflation = inflation.loc[last_date, 'corePCE']\n",
    "# calculate multiplier\n",
    "inflation['inflationMultiplier'] = today_inflation/inflation.corePCE\n",
    "# export csv\n",
    "inflation.to_csv('../data/preSQL/inflation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb73497",
   "metadata": {},
   "source": [
    "## 10-K Statements\n",
    "- Balance Sheet, Cash Flow and Income Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107806a",
   "metadata": {},
   "source": [
    "#### Walk the path in a directory and generate the dataframe.\n",
    "- We're only interested in dates when the symbol belonged to the sp500\n",
    "- Risk: get the past value of a current ticker instead of getting the values of a former ticker at that time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cdae054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv(path):\n",
    "    df_list = []\n",
    "    path_dir = Path(path)\n",
    "    sp500_dates = pd.read_csv('../data/raw/sp500_movements.csv')\n",
    "    sp500_dates.removed = sp500_dates.removed.replace('not_yet_removed', '2022-12-31')\n",
    "    sp500_dates.added = pd.to_datetime(sp500_dates.added)\n",
    "    sp500_dates.removed = pd.to_datetime(sp500_dates.removed)\n",
    "    for file in path_dir.glob('*.csv'):\n",
    "        csv_path = os.path.join(file.parent, file.name)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # convert fillingDates to datetime\n",
    "        df.fillingDate = pd.to_datetime(df.fillingDate)\n",
    "        # keep only the the combinations of symbol and date which belonged to the sp500\n",
    "        mask = sp500_dates.symbol == file.name.split('.')[0]\n",
    "        added = sp500_dates[mask].added\n",
    "        removed = sp500_dates[mask].removed\n",
    "        for stay in tuple(zip(added, removed)):\n",
    "            df_list.append(df[df.fillingDate.between(stay[0], stay[1])])\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf4a29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_merge():\n",
    "    balance = merge_csv('../data/raw/balance')\n",
    "    balance.to_csv('../data/raw/balance.csv', index=False)\n",
    "    print(balance.shape)\n",
    "\n",
    "    cash_flow = merge_csv('../data/raw/cash_flow')\n",
    "    cash_flow.to_csv('../data/raw/cash_flow.csv', index=False)\n",
    "    print(cash_flow.shape)\n",
    "\n",
    "    income = merge_csv('../data/raw/income')\n",
    "    income.to_csv('../data/raw/income.csv', index=False)\n",
    "    print(income.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c809ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10179, 54)\n",
      "(10309, 40)\n",
      "(10328, 38)\n"
     ]
    }
   ],
   "source": [
    "# do_merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7003cc8a",
   "metadata": {},
   "source": [
    "### Table for the join of all the historical financial statements in the SP500\n",
    "- Generate the primary keys\n",
    "- Clean the primary keys: symbol + year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02320897",
   "metadata": {},
   "source": [
    "#### Generate the primary keys of symbol, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f772a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_dates = pd.read_csv('../data/raw/sp500_movements.csv')\n",
    "sp500_dates.removed = sp500_dates.removed.replace('not_yet_removed', '2022-12-31')\n",
    "sp500_dates.added = pd.to_datetime(sp500_dates.added).dt.year\n",
    "sp500_dates.removed = pd.to_datetime(sp500_dates.removed).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56852c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for ticker in sp500_dates.symbol.unique():\n",
    "    mask = sp500_dates.symbol == ticker \n",
    "    added = sp500_dates[mask].added\n",
    "    removed = sp500_dates[mask].removed\n",
    "    for stay in tuple(zip(added, removed)):\n",
    "        # convert to years and generate their sequence\n",
    "        yearlist = list(range(stay[0], stay[1])) # get two years prior for increases\n",
    "        for y in yearlist:\n",
    "            indices.append((ticker, y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9318d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = pd.DataFrame(index = set(indices)).reset_index()\n",
    "statements.columns = ['symbol', 'calendarYear']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0dd32",
   "metadata": {},
   "source": [
    "#### Left join with balance, cash flow and income statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9e33f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = pd.read_csv('../data/raw/balance.csv')\n",
    "cash_flow = pd.read_csv('../data/raw/cash_flow.csv')\n",
    "income = pd.read_csv('../data/raw/income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ccbcb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = statements.merge(right = balance, on = ['symbol', 'calendarYear'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9afcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = statements.merge(right = income, on = ['symbol', 'calendarYear'], how='left')\n",
    "statements = statements.merge(right = cash_flow, on = ['symbol', 'calendarYear'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f037f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements.to_csv('../data/raw/statements.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7035433",
   "metadata": {},
   "source": [
    "#### Drop duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f037f433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12985, 128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statements = pd.read_csv('../data/raw/statements.csv')\n",
    "statements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f8a2e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12985, 109)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated = [\n",
    "    ['date','date_x','date_y'],\n",
    "    ['acceptedDate','acceptedDate_x','acceptedDate_y'],\n",
    "    ['cik','cik_x','cik_y'],\n",
    "    ['depreciationAndAmortization_x','depreciationAndAmortization_y'],\n",
    "    ['fillingDate', 'fillingDate_x','fillingDate_y'],\n",
    "    ['finalLink','finalLink_x','finalLink_y'],\n",
    "    ['inventory_x','inventory_y'],\n",
    "    ['link','link_x','link_y'],\n",
    "    ['netIncome_x','netIncome_y'],\n",
    "    ['period','period_x','period_y'],\n",
    "    ['reportedCurrency','reportedCurrency_x','reportedCurrency_y',]\n",
    "]\n",
    "for group in repeated:\n",
    "    base_feature = group[0]\n",
    "    for dup_feature in group[1:]:\n",
    "        statements[base_feature] = statements[base_feature].fillna(statements[dup_feature])\n",
    "        statements = statements.drop(columns=dup_feature)    \n",
    "statements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5ee36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_rename = {\n",
    "    'depreciationAndAmortization_x': 'depreciationAndAmortization',\n",
    "    'inventory_x': 'inventory',\n",
    "    'netIncome_x': 'netIncome',\n",
    "}\n",
    "statements = statements.rename(columns=col_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9379f69",
   "metadata": {},
   "source": [
    "#### Convert to billions and adjust for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "450caacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to billions\n",
    "for feat in to_billions_features:\n",
    "    statements[feat] = statements[feat].astype(float)/1e9\n",
    "# sort values\n",
    "statements = statements.sort_values(by=['symbol', 'calendarYear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d97d7",
   "metadata": {},
   "source": [
    "Adjust for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bbcd70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpala\\AppData\\Local\\Temp\\ipykernel_24696\\2507109666.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  statements['month'] = statements['date'].dt.month\n"
     ]
    }
   ],
   "source": [
    "statements['date'] = pd.to_datetime(statements['date'])\n",
    "statements['month'] = statements['date'].dt.month\n",
    "inflation = pd.read_csv('../data/clean/inflation.csv')\n",
    "inflation = inflation.rename(columns={'year':'calendarYear'})\n",
    "statements = statements.merge(\n",
    "    right = inflation.loc[:,['calendarYear','month','inflationMultiplier']],\n",
    "    how='left', \n",
    "    left_on=['calendarYear', 'month'], \n",
    "    right_on = ['calendarYear', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e20a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in to_billions_features:\n",
    "    statements[feat] = statements[feat] * statements.inflationMultiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1fd9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements.to_csv('../data/clean/statements.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc4d94",
   "metadata": {},
   "source": [
    "## Market Capitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb6d79",
   "metadata": {},
   "source": [
    "#### Target variable. Join with the statements dataframe on filingDate + 10 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e54196",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = pd.read_csv('../data/clean/statements.csv')\n",
    "filldate_mask = statements.fillingDate.notnull()\n",
    "symbols = statements[filldate_mask].symbol.unique()\n",
    "# add 10 days to let the price stabilize\n",
    "statements['mcapDate'] = pd.to_datetime(statements.fillingDate) + datetime.timedelta(10)\n",
    "# extract year and week from that date\n",
    "statements['mcapYear'] = statements.mcapDate.dt.year\n",
    "statements['mcapWeek'] = statements.mcapDate.dt.isocalendar().week\n",
    "# createa target column\n",
    "statements['target'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c59880",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in symbols:\n",
    "    # open the market caps dataframe\n",
    "    try:\n",
    "        df = pd.read_csv('../data/raw/marketCaps/{}.csv'.format(ticker)).sort_values(by='date').reset_index(drop='True')\n",
    "    except:\n",
    "        continue\n",
    "    # convert market cap to billions\n",
    "    df.marketCap = df.marketCap/1e9\n",
    "    # exctract year and week\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df['mcapYear'] = df.date.dt.year\n",
    "    df['mcapWeek'] = df.date.dt.isocalendar().week\n",
    "    df['marketCapSMA10'] = df.marketCap.rolling(10).mean()\n",
    "    df = df.rename(columns={'date':'mcapDate'})\n",
    "    df.to_csv('../data/raw/marketCaps/{}_clean.csv'.format(ticker), index=False)\n",
    "    # attempt o left join on statements on mcapDdate \n",
    "    statements = statements.merge(\n",
    "        right=df.loc[:,['symbol','mcapDate','marketCapSMA10']],\n",
    "        on = ['symbol', 'mcapDate'],\n",
    "        how='left'\n",
    "    )\n",
    "    # update values and drop column\n",
    "    statements.target = statements.target.fillna(statements.marketCapSMA10)\n",
    "    statements = statements.drop(columns='marketCapSMA10')\n",
    "    # join again on mcapYear and mcapYeek in case the date does not exist\n",
    "    statements = statements.merge(\n",
    "            right=df.groupby(['symbol','mcapYear', 'mcapWeek']).marketCapSMA10.mean(),\n",
    "            on = ['symbol', 'mcapYear', 'mcapWeek'],\n",
    "            how='left'\n",
    "    )\n",
    "    # update values and drop column\n",
    "    statements.target = statements.target.fillna(statements.marketCapSMA10)\n",
    "    statements = statements.drop(columns='marketCapSMA10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22e050",
   "metadata": {},
   "source": [
    "Adjust inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7a911bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements.target = statements.inflationMultiplier * statements.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9146900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements.to_csv('../data/clean/statements_mcap.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d35b5d",
   "metadata": {},
   "source": [
    "#### Aditional Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d7ec9",
   "metadata": {},
   "source": [
    "# Null Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23a7079a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12985, 115)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/clean/statements_mcap.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a58b8",
   "metadata": {},
   "source": [
    "#### Drop all rows with null target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d917a080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                                     0.197290\n",
       "finalLink                                0.197290\n",
       "cik                                      0.032517\n",
       "totalLiabilitiesAndStockholdersEquity    0.010943\n",
       "retainedEarnings                         0.010943\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['target']\n",
    "data = data.dropna(subset=cols)\n",
    "(data.isna().sum() / len(data)).sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4ba991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9595, 115)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41bb0d1",
   "metadata": {},
   "source": [
    "#### Duplicates clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96769527",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['symbol', 'calendarYear'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a62b98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>calendarYear</th>\n",
       "      <th>date</th>\n",
       "      <th>fillingDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [symbol, calendarYear, date, fillingDate]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask =data.duplicated(subset=['symbol', 'calendarYear'], keep=False)\n",
    "data[mask].sort_values(by='date').loc[:, ['symbol', 'calendarYear', 'date', 'fillingDate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c5ce69",
   "metadata": {},
   "source": [
    "# Incorrect observations clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e517e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(data, symbol, dates_inclusive):\n",
    "    drop_mask = (data.symbol == symbol) & data.calendarYear.between(dates_inclusive[0], dates_inclusive[1])\n",
    "    idx_drop = data[drop_mask].index\n",
    "    return data.drop(index=idx_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc13f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.symbol == 'NBR'\n",
    "data.loc[mask, 'target'] = data.loc[mask, 'target']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00d0d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = drop_rows(data, 'MBI', [2002,2008])\n",
    "data = drop_rows(data, 'SLM', [2004,2013])\n",
    "data = drop_rows(data, 'STI', [2002,2009])\n",
    "data = drop_rows(data, 'CHK', [2006,2017])\n",
    "data = drop_rows(data, 'SIG', [2016,2016])\n",
    "data = drop_rows(data, 'SYMC', [2010,2010])\n",
    "data = drop_rows(data, 'THC', [2002,2002])\n",
    "data = drop_rows(data, 'CBS', [2005,2012])\n",
    "data = drop_rows(data, 'SUN', [2010,2011])\n",
    "data = drop_rows(data, 'TT', [2002,2007])\n",
    "data = drop_rows(data, 'KMG', [1999,2005])\n",
    "data = drop_rows(data, 'MO', [1996,2007])\n",
    "data = drop_rows(data, 'GILD', [2013,2014])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba5e6387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9492, 115)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e0d70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/processed/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c538b6",
   "metadata": {},
   "source": [
    "## Economic Situation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5866cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = Path('../data/raw/fred')\n",
    "for i, file in enumerate(path_dir.glob('*.csv')):\n",
    "    csv_path = os.path.join(file.parent, file.name)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if i == 0:\n",
    "        fred = df.copy()\n",
    "    else:\n",
    "        fred = fred.merge(df, on=['date', 'year', 'month', 'day'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6015852",
   "metadata": {},
   "outputs": [],
   "source": [
    "fred.date = pd.to_datetime(fred.date)\n",
    "fred = fred.set_index('date').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d05b88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-04-19 00:00:00')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fred.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e82f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range('01-01-1991', '2022-04-19')\n",
    "fred = fred.reindex(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c882a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fred = fred.interpolate()\n",
    "fred.to_csv('../data/clean/fred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a5265",
   "metadata": {},
   "source": [
    "## join with market caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fe78fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b312ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillingDate = pd.to_datetime(data.fillingDate)\n",
    "data = data.merge(\n",
    "    fred.drop(columns = ['year', 'month', 'day']),\n",
    "    how = 'left',\n",
    "    left_on='fillingDate',\n",
    "    right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22837936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/processed/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d3c6922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['symbol',\n",
       " 'calendarYear',\n",
       " 'cashAndCashEquivalents',\n",
       " 'shortTermInvestments',\n",
       " 'cashAndShortTermInvestments',\n",
       " 'netReceivables',\n",
       " 'inventory',\n",
       " 'otherCurrentAssets',\n",
       " 'totalCurrentAssets',\n",
       " 'propertyPlantEquipmentNet',\n",
       " 'goodwill',\n",
       " 'intangibleAssets',\n",
       " 'goodwillAndIntangibleAssets',\n",
       " 'longTermInvestments',\n",
       " 'taxAssets',\n",
       " 'otherNonCurrentAssets',\n",
       " 'totalNonCurrentAssets',\n",
       " 'otherAssets',\n",
       " 'totalAssets',\n",
       " 'accountPayables',\n",
       " 'shortTermDebt',\n",
       " 'taxPayables',\n",
       " 'deferredRevenue',\n",
       " 'otherCurrentLiabilities',\n",
       " 'totalCurrentLiabilities',\n",
       " 'longTermDebt',\n",
       " 'deferredRevenueNonCurrent',\n",
       " 'deferredTaxLiabilitiesNonCurrent',\n",
       " 'otherNonCurrentLiabilities',\n",
       " 'totalNonCurrentLiabilities',\n",
       " 'otherLiabilities',\n",
       " 'capitalLeaseObligations',\n",
       " 'totalLiabilities',\n",
       " 'preferredStock',\n",
       " 'commonStock',\n",
       " 'retainedEarnings',\n",
       " 'accumulatedOtherComprehensiveIncomeLoss',\n",
       " 'othertotalStockholdersEquity',\n",
       " 'totalStockholdersEquity',\n",
       " 'totalLiabilitiesAndStockholdersEquity',\n",
       " 'minorityInterest',\n",
       " 'totalEquity',\n",
       " 'totalLiabilitiesAndTotalEquity',\n",
       " 'totalInvestments',\n",
       " 'totalDebt',\n",
       " 'netDebt',\n",
       " 'revenue',\n",
       " 'costOfRevenue',\n",
       " 'grossProfit',\n",
       " 'grossProfitRatio',\n",
       " 'researchAndDevelopmentExpenses',\n",
       " 'generalAndAdministrativeExpenses',\n",
       " 'sellingAndMarketingExpenses',\n",
       " 'sellingGeneralAndAdministrativeExpenses',\n",
       " 'otherExpenses',\n",
       " 'operatingExpenses',\n",
       " 'costAndExpenses',\n",
       " 'interestIncome',\n",
       " 'interestExpense',\n",
       " 'depreciationAndAmortization',\n",
       " 'ebitda',\n",
       " 'ebitdaratio',\n",
       " 'operatingIncome',\n",
       " 'operatingIncomeRatio',\n",
       " 'totalOtherIncomeExpensesNet',\n",
       " 'incomeBeforeTax',\n",
       " 'incomeBeforeTaxRatio',\n",
       " 'incomeTaxExpense',\n",
       " 'netIncome',\n",
       " 'netIncomeRatio',\n",
       " 'eps',\n",
       " 'epsdiluted',\n",
       " 'weightedAverageShsOut',\n",
       " 'weightedAverageShsOutDil',\n",
       " 'date',\n",
       " 'reportedCurrency',\n",
       " 'cik',\n",
       " 'fillingDate',\n",
       " 'acceptedDate',\n",
       " 'period',\n",
       " 'deferredIncomeTax',\n",
       " 'stockBasedCompensation',\n",
       " 'changeInWorkingCapital',\n",
       " 'accountsReceivables',\n",
       " 'accountsPayables',\n",
       " 'otherWorkingCapital',\n",
       " 'otherNonCashItems',\n",
       " 'netCashProvidedByOperatingActivities',\n",
       " 'investmentsInPropertyPlantAndEquipment',\n",
       " 'acquisitionsNet',\n",
       " 'purchasesOfInvestments',\n",
       " 'salesMaturitiesOfInvestments',\n",
       " 'otherInvestingActivites',\n",
       " 'netCashUsedForInvestingActivites',\n",
       " 'debtRepayment',\n",
       " 'commonStockIssued',\n",
       " 'commonStockRepurchased',\n",
       " 'dividendsPaid',\n",
       " 'otherFinancingActivites',\n",
       " 'netCashUsedProvidedByFinancingActivities',\n",
       " 'effectOfForexChangesOnCash',\n",
       " 'netChangeInCash',\n",
       " 'cashAtEndOfPeriod',\n",
       " 'cashAtBeginningOfPeriod',\n",
       " 'operatingCashFlow',\n",
       " 'capitalExpenditure',\n",
       " 'freeCashFlow',\n",
       " 'link',\n",
       " 'finalLink',\n",
       " 'month',\n",
       " 'inflationMultiplier',\n",
       " 'mcapDate',\n",
       " 'mcapYear',\n",
       " 'mcapWeek',\n",
       " 'target',\n",
       " 'brent',\n",
       " 'chicagoFedFinancialConditions',\n",
       " 'consumerSentiment',\n",
       " 'corePCE',\n",
       " 'GDP',\n",
       " 'interest10Y',\n",
       " 'interest10Y3M',\n",
       " 'interest10YIInflationAdjusted',\n",
       " 'interest20Y',\n",
       " 'interest3M',\n",
       " 'inventorySalesRatio',\n",
       " 'leadingIndex',\n",
       " 'monthlySupplyHouses',\n",
       " 'moodysAaa20Y',\n",
       " 'moodysBaa20Y',\n",
       " 'mortgage30Y',\n",
       " 'nasdaq',\n",
       " 'stlouisFredFinancialStress',\n",
       " 'unemployment',\n",
       " 'volatility',\n",
       " 'wilshire5000',\n",
       " 'wti']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a8e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8ec8f4bfe78eccfa1d1de3a91d61a30d0bd8efad5c2f5d61c7b5760b6b34097"
  },
  "kernelspec": {
   "display_name": "sp500",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
