{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.cluster import KMeans\n",
    "# bayestian hyperparameter tunning\n",
    "import optuna\n",
    "# models to try\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from myvars import input_features\n",
    "from myfuncs import num_describe, generate_features\n",
    "from myclasses import Windsorizer\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y, y_pred, **kwargs):\n",
    "    return mean_squared_error(y_true=np.exp(y), y_pred=np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data():\n",
    "    data = pd.read_csv('../data/processed/data.csv')\n",
    "    data = data.dropna(subset=input_features)\n",
    "    data = generate_features(data)\n",
    "    data.query(\"calendarYear > 2018\").to_csv('../data/processed/future.csv', index=False)\n",
    "    data.query(\"calendarYear <= 2018\").to_csv('../data/processed/present.csv', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/present.csv')\n",
    "features = data.drop(columns=['target', 'symbol', 'calendarYear', 'filingDate'])\n",
    "target = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5925, 62), (1975, 62), (5925,), (1975,)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    np.log(target), \n",
    "    test_size=0.25, \n",
    "    random_state = 46)\n",
    "[x.shape for x in [X_train, X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_train,y_train], axis=1).to_csv('../data/processed/train.csv', index=False)\n",
    "pd.concat([X_test,y_test], axis=1).to_csv('../data/processed/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4624.240947756172"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(y_test)\n",
    "mean = y_train.mean()\n",
    "worst_preds = np.tile(mean, n)\n",
    "mean_squared_error(y_true=np.exp(y_test), y_pred = np.exp(worst_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_linear_regression(pipe, X_train, X_test, y_train, y_test=None):\n",
    "    pipe.steps.append(('linear_regression', LinearRegression()))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds_test = pipe.predict(X_test)\n",
    "    preds_train = pipe.predict(X_train)\n",
    "    mse_test = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds_test))\n",
    "    mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(preds_train))\n",
    "    print('mse train:', mse_train)\n",
    "    print('mse test: ', mse_test)\n",
    "    print('rmse test: ', np.sqrt(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 999.3981651467957\n",
      "mse test:  663.5715545296208\n",
      "rmse test:  25.759882657528173\n"
     ]
    }
   ],
   "source": [
    "mypipe = Pipeline(steps=[\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ])\n",
    "do_linear_regression(mypipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 338.83474939613353\n",
      "mse test:  2.6017074875005544e+113\n",
      "rmse test:  5.100693568036169e+56\n"
     ]
    }
   ],
   "source": [
    "def do_poly_regression(pipe, X_train, X_test, y_train, y_test=None, degree = 2):\n",
    "    pipe.steps.append(('poly_transform', PolynomialFeatures(degree=degree)))\n",
    "    pipe.steps.append(('regression', LinearRegression()))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds_test = pipe.predict(X_test)\n",
    "    preds_train = pipe.predict(X_train)\n",
    "    mse_test = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds_test))\n",
    "    mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(preds_train))\n",
    "    print('mse train:', mse_train)\n",
    "    print('mse test: ', mse_test)\n",
    "    print('rmse test: ', np.sqrt(mse_test))\n",
    "\n",
    "mypipe = Pipeline(steps=[\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ])\n",
    "do_poly_regression(mypipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Insane Overfit**. 1e113 order of magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 1033.6502283339767\n",
      "mse test:  686.7258782508286\n",
      "rmse test:  26.205455123901753\n"
     ]
    }
   ],
   "source": [
    "def do_linear_svm_regression(pipe, X_train, X_test, y_train, y_test=None):\n",
    "    pipe.steps.append(('linear_svm', LinearSVR(C=0.02)))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds_test = pipe.predict(X_test)\n",
    "    preds_train = pipe.predict(X_train)\n",
    "    mse_test = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds_test))\n",
    "    mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(preds_train))\n",
    "    print('mse train:', mse_train)\n",
    "    print('mse test: ', mse_test)\n",
    "    print('rmse test: ', np.sqrt(mse_test))\n",
    "\n",
    "mypipe = Pipeline(steps=[\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ])\n",
    "do_linear_svm_regression(mypipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check ill-conditioning. For C's larger than 0.02 it stops converging despite max_iter being 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with radial basis functions\n",
    "- Nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 449.51700186471805\n",
      "mse test:  481.71800049745985\n",
      "rmse test:  21.948075097772467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', PowerTransformer()), ('rbf_svm', SVR(C=1.5))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_svm_regression(pipe, X_train, X_test, y_train, y_test=None):\n",
    "    pipe.steps.append(('rbf_svm', SVR(kernel = 'rbf', C=1.5, epsilon=0.1)))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds_test = pipe.predict(X_test)\n",
    "    preds_train = pipe.predict(X_train)\n",
    "    mse_test = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds_test))\n",
    "    mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(preds_train))\n",
    "    print('mse train:', mse_train)\n",
    "    print('mse test: ', mse_test)\n",
    "    print('rmse test: ', np.sqrt(mse_test))\n",
    "    return pipe\n",
    "\n",
    "mypipe = Pipeline(steps=[\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ])\n",
    "do_svm_regression(mypipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 483.4397437974652\n",
      "mse test:  469.06610344014774\n",
      "rmse test:  21.657933960563916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', PowerTransformer()),\n",
       "                ('rfe',\n",
       "                 RFE(estimator=LinearRegression(), n_features_to_select=2)),\n",
       "                ('knn', KNeighborsRegressor(n_neighbors=8))])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_neighbors(pipe, X_train, X_test, y_train, y_test=None):\n",
    "    pipe.steps.append(('rfe', RFE(estimator = LinearRegression(), n_features_to_select = 2)))\n",
    "    pipe.steps.append(('knn', KNeighborsRegressor(n_neighbors=8)))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds_test = pipe.predict(X_test)\n",
    "    preds_train = pipe.predict(X_train)\n",
    "    mse_test = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds_test))\n",
    "    mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(preds_train))\n",
    "    print('mse train:', mse_train)\n",
    "    print('mse test: ', mse_test)\n",
    "    print('rmse test: ', np.sqrt(mse_test))\n",
    "    return pipe\n",
    "\n",
    "mypipe = Pipeline(steps=[\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ])\n",
    "do_neighbors(mypipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 483.4397437974652\n",
      "mse test:  469.06610344014774\n",
      "rmse test:  21.657933960563916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', PowerTransformer()),\n",
       "                ('rfe',\n",
       "                 RFE(estimator=LinearRegression(), n_features_to_select=2)),\n",
       "                ('knn', KNeighborsRegressor(n_neighbors=8))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_forest(pipe, X_train, X_test, y_train, y_test=None):\n",
    "    pipe.steps.append(('forest', RandomForestRegressor()))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds_test = pipe.predict(X_test)\n",
    "    preds_train = pipe.predict(X_train)\n",
    "    mse_test = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds_test))\n",
    "    mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(preds_train))\n",
    "    print('mse train:', mse_train)\n",
    "    print('mse test: ', mse_test)\n",
    "    print('rmse test: ', np.sqrt(mse_test))\n",
    "    return pipe\n",
    "\n",
    "mypipe = Pipeline(steps=[\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ])\n",
    "do_neighbors(mypipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 483.4397437974652\n",
      "mse test:  469.06610344014774\n",
      "rmse test:  21.657933960563916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', PowerTransformer()),\n",
       "                ('rfe',\n",
       "                 RFE(estimator=LinearRegression(), n_features_to_select=2)),\n",
       "                ('knn', KNeighborsRegressor(n_neighbors=8))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_forest(pipe, X_train, X_test, y_train, y_test=None):\n",
    "    pipe.steps.append(('rfe', RFE(estimator = LinearRegression(), n_features_to_select = 2)))\n",
    "    pipe.steps.append(('knn', KNeighborsRegressor(n_neighbors=8)))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds_test = pipe.predict(X_test)\n",
    "    preds_train = pipe.predict(X_train)\n",
    "    mse_test = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds_test))\n",
    "    mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(preds_train))\n",
    "    print('mse train:', mse_train)\n",
    "    print('mse test: ', mse_test)\n",
    "    print('rmse test: ', np.sqrt(mse_test))\n",
    "    return pipe\n",
    "\n",
    "mypipe = Pipeline(steps=[\n",
    "    ('scaler', PowerTransformer()),\n",
    "    ])\n",
    "do_neighbors(mypipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predictions_dataframe(dict):\n",
    "    df = pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5816</th>\n",
       "      <td>26.68441</td>\n",
       "      <td>25.74952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>250.56730</td>\n",
       "      <td>444.01120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>9.68725</td>\n",
       "      <td>7.22381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>3.63026</td>\n",
       "      <td>3.35654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>36.56533</td>\n",
       "      <td>43.25363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6907</th>\n",
       "      <td>17.78977</td>\n",
       "      <td>17.01301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>10.81797</td>\n",
       "      <td>10.24911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>13.78154</td>\n",
       "      <td>10.69068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>22.82605</td>\n",
       "      <td>28.39432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>6.88143</td>\n",
       "      <td>5.17596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted      real\n",
       "5816   26.68441  25.74952\n",
       "3072  250.56730 444.01120\n",
       "5412    9.68725   7.22381\n",
       "5202    3.63026   3.35654\n",
       "265    36.56533  43.25363\n",
       "...         ...       ...\n",
       "6907   17.78977  17.01301\n",
       "6476   10.81797  10.24911\n",
       "7893   13.78154  10.69068\n",
       "6604   22.82605  28.39432\n",
       "3000    6.88143   5.17596\n",
       "\n",
       "[1975 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(zip(np.exp(preds), np.exp(y_test)), columns=['predicted', 'real'], index=X_test.index)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>calendarYear</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "      <th>previousMarketCap</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-09-29</td>\n",
       "      <td>640.96695</td>\n",
       "      <td>224.62506</td>\n",
       "      <td>326.03867</td>\n",
       "      <td>-416.34190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>823.17064</td>\n",
       "      <td>433.22416</td>\n",
       "      <td>644.27240</td>\n",
       "      <td>-389.94648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>756.45198</td>\n",
       "      <td>411.99827</td>\n",
       "      <td>578.54152</td>\n",
       "      <td>-344.45371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>AIG</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>364.13380</td>\n",
       "      <td>151.52251</td>\n",
       "      <td>248.23655</td>\n",
       "      <td>-212.61129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014-02-26</td>\n",
       "      <td>488.00373</td>\n",
       "      <td>284.22978</td>\n",
       "      <td>478.35440</td>\n",
       "      <td>-203.77395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>INTC</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009-02-23</td>\n",
       "      <td>90.36752</td>\n",
       "      <td>154.31599</td>\n",
       "      <td>154.53892</td>\n",
       "      <td>63.94848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>138.70783</td>\n",
       "      <td>206.27244</td>\n",
       "      <td>334.54178</td>\n",
       "      <td>67.56461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>GE</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>133.59204</td>\n",
       "      <td>204.65317</td>\n",
       "      <td>285.03982</td>\n",
       "      <td>71.06113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>T</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>241.21551</td>\n",
       "      <td>317.21278</td>\n",
       "      <td>642.79239</td>\n",
       "      <td>75.99727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>WEN</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>0.85840</td>\n",
       "      <td>144.99660</td>\n",
       "      <td>0.77027</td>\n",
       "      <td>144.13820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol  calendarYear  filingDate      real  predicted  previousMarketCap  \\\n",
       "1826   CSCO          2000  2000-09-29 640.96695  224.62506          326.03867   \n",
       "3194  GOOGL          2017  2018-02-06 823.17064  433.22416          644.27240   \n",
       "3181   GOOG          2017  2018-02-06 756.45198  411.99827          578.54152   \n",
       "339     AIG          2000  2000-12-31 364.13380  151.52251          248.23655   \n",
       "7794    XOM          2013  2014-02-26 488.00373  284.22978          478.35440   \n",
       "...     ...           ...         ...       ...        ...                ...   \n",
       "3738   INTC          2008  2009-02-23  90.36752  154.31599          154.53892   \n",
       "5499   ORCL          2001  2001-05-31 138.70783  206.27244          334.54178   \n",
       "3086     GE          2017  2018-02-23 133.59204  204.65317          285.03982   \n",
       "6730      T          1999  1999-12-31 241.21551  317.21278          642.79239   \n",
       "7520    WEN          2000  2001-04-02   0.85840  144.99660            0.77027   \n",
       "\n",
       "          error  \n",
       "1826 -416.34190  \n",
       "3194 -389.94648  \n",
       "3181 -344.45371  \n",
       "339  -212.61129  \n",
       "7794 -203.77395  \n",
       "...         ...  \n",
       "3738   63.94848  \n",
       "5499   67.56461  \n",
       "3086   71.06113  \n",
       "6730   75.99727  \n",
       "7520  144.13820  \n",
       "\n",
       "[1975 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions = pd.concat([data.loc[X_test.index,:], predictions], axis=1)\n",
    "df_predictions = df_predictions.sort_values(by = ['symbol', 'calendarYear'])[['symbol','calendarYear','filingDate','real', 'predicted','previousMarketCap']]\n",
    "df_predictions['error'] = (df_predictions.predicted - df_predictions.real)\n",
    "df_predictions.sort_values(by='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>calendarYear</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "      <th>previousMarketCap</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>823.17064</td>\n",
       "      <td>316.05172</td>\n",
       "      <td>644.27240</td>\n",
       "      <td>-507.11892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>756.45198</td>\n",
       "      <td>320.13676</td>\n",
       "      <td>578.54152</td>\n",
       "      <td>-436.31522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-09-29</td>\n",
       "      <td>640.96695</td>\n",
       "      <td>237.47861</td>\n",
       "      <td>326.03867</td>\n",
       "      <td>-403.48835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014-02-26</td>\n",
       "      <td>488.00373</td>\n",
       "      <td>225.88919</td>\n",
       "      <td>478.35440</td>\n",
       "      <td>-262.11453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>478.35440</td>\n",
       "      <td>228.62606</td>\n",
       "      <td>499.72205</td>\n",
       "      <td>-249.72835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>FB</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>612.07527</td>\n",
       "      <td>370.93908</td>\n",
       "      <td>440.98280</td>\n",
       "      <td>-241.13618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7792</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>499.72205</td>\n",
       "      <td>263.45634</td>\n",
       "      <td>528.47053</td>\n",
       "      <td>-236.26572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>AIG</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>364.13380</td>\n",
       "      <td>144.68086</td>\n",
       "      <td>248.23655</td>\n",
       "      <td>-219.45294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>GE</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>389.20414</td>\n",
       "      <td>182.12229</td>\n",
       "      <td>250.48968</td>\n",
       "      <td>-207.08184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-09-28</td>\n",
       "      <td>504.30292</td>\n",
       "      <td>309.31759</td>\n",
       "      <td>749.62339</td>\n",
       "      <td>-194.98533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>GE</td>\n",
       "      <td>2003</td>\n",
       "      <td>2004-03-01</td>\n",
       "      <td>444.01120</td>\n",
       "      <td>255.74898</td>\n",
       "      <td>350.66415</td>\n",
       "      <td>-188.26222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7780</th>\n",
       "      <td>XOM</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>432.02958</td>\n",
       "      <td>247.00583</td>\n",
       "      <td>408.81038</td>\n",
       "      <td>-185.02376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>INTC</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002-03-13</td>\n",
       "      <td>321.78971</td>\n",
       "      <td>155.28778</td>\n",
       "      <td>284.13555</td>\n",
       "      <td>-166.50193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>GE</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008-02-20</td>\n",
       "      <td>424.14577</td>\n",
       "      <td>258.06713</td>\n",
       "      <td>455.01546</td>\n",
       "      <td>-166.07864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>435.72527</td>\n",
       "      <td>273.97063</td>\n",
       "      <td>426.64532</td>\n",
       "      <td>-161.75464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>T</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>301.57010</td>\n",
       "      <td>155.27219</td>\n",
       "      <td>145.59525</td>\n",
       "      <td>-146.29791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>426.64532</td>\n",
       "      <td>286.19073</td>\n",
       "      <td>322.05853</td>\n",
       "      <td>-140.45459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-09-05</td>\n",
       "      <td>436.79820</td>\n",
       "      <td>300.41615</td>\n",
       "      <td>378.67650</td>\n",
       "      <td>-136.38205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004-01-31</td>\n",
       "      <td>338.81402</td>\n",
       "      <td>202.61154</td>\n",
       "      <td>300.77608</td>\n",
       "      <td>-136.20249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>BAC</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006-12-31</td>\n",
       "      <td>320.87523</td>\n",
       "      <td>197.23433</td>\n",
       "      <td>254.69374</td>\n",
       "      <td>-123.64090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7799</th>\n",
       "      <td>XOM</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>367.80671</td>\n",
       "      <td>250.78715</td>\n",
       "      <td>361.04152</td>\n",
       "      <td>-117.01957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>285.94380</td>\n",
       "      <td>175.08838</td>\n",
       "      <td>246.22943</td>\n",
       "      <td>-110.85542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7290</th>\n",
       "      <td>V</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>344.20149</td>\n",
       "      <td>234.13817</td>\n",
       "      <td>291.87830</td>\n",
       "      <td>-110.06332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>CVX</td>\n",
       "      <td>2016</td>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>238.62691</td>\n",
       "      <td>129.93909</td>\n",
       "      <td>184.75681</td>\n",
       "      <td>-108.68782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>C</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>126.32043</td>\n",
       "      <td>20.36587</td>\n",
       "      <td>10.81618</td>\n",
       "      <td>-105.95456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7621</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-01-31</td>\n",
       "      <td>300.77608</td>\n",
       "      <td>198.54078</td>\n",
       "      <td>300.77608</td>\n",
       "      <td>-102.23530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>PFE</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>311.83217</td>\n",
       "      <td>211.86300</td>\n",
       "      <td>397.42362</td>\n",
       "      <td>-99.96917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7541</th>\n",
       "      <td>WFC</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>183.61238</td>\n",
       "      <td>83.75846</td>\n",
       "      <td>60.09221</td>\n",
       "      <td>-99.85392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>BA</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>230.80512</td>\n",
       "      <td>132.73587</td>\n",
       "      <td>117.66781</td>\n",
       "      <td>-98.06926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>MRK</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>277.38173</td>\n",
       "      <td>179.53987</td>\n",
       "      <td>249.18366</td>\n",
       "      <td>-97.84187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>UNH</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>248.58807</td>\n",
       "      <td>152.65083</td>\n",
       "      <td>176.65271</td>\n",
       "      <td>-95.93724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>PG</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-08-08</td>\n",
       "      <td>285.00460</td>\n",
       "      <td>190.93958</td>\n",
       "      <td>234.05602</td>\n",
       "      <td>-94.06502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>INTC</td>\n",
       "      <td>2003</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>275.29992</td>\n",
       "      <td>183.69287</td>\n",
       "      <td>164.89576</td>\n",
       "      <td>-91.60705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>FB</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>344.48681</td>\n",
       "      <td>259.58671</td>\n",
       "      <td>249.43595</td>\n",
       "      <td>-84.90010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>KDP</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-14</td>\n",
       "      <td>101.78178</td>\n",
       "      <td>19.84647</td>\n",
       "      <td>19.58540</td>\n",
       "      <td>-81.93531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>206.45937</td>\n",
       "      <td>126.65237</td>\n",
       "      <td>111.57360</td>\n",
       "      <td>-79.80699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>VZ</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>227.31811</td>\n",
       "      <td>148.87430</td>\n",
       "      <td>216.13538</td>\n",
       "      <td>-78.44381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>HD</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>226.42715</td>\n",
       "      <td>155.87431</td>\n",
       "      <td>200.18051</td>\n",
       "      <td>-70.55284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>GE</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>261.60994</td>\n",
       "      <td>192.33677</td>\n",
       "      <td>207.97261</td>\n",
       "      <td>-69.27317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>TXN</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>133.33469</td>\n",
       "      <td>65.64159</td>\n",
       "      <td>55.09022</td>\n",
       "      <td>-67.69310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>VZ</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>235.72019</td>\n",
       "      <td>172.09517</td>\n",
       "      <td>190.55209</td>\n",
       "      <td>-63.62502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>KMI</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>103.58548</td>\n",
       "      <td>40.69058</td>\n",
       "      <td>39.09912</td>\n",
       "      <td>-62.89490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>VZ</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>172.61872</td>\n",
       "      <td>111.10735</td>\n",
       "      <td>118.52306</td>\n",
       "      <td>-61.51137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>IBM</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012-02-28</td>\n",
       "      <td>284.15342</td>\n",
       "      <td>224.35928</td>\n",
       "      <td>249.40784</td>\n",
       "      <td>-59.79413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>F</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010-02-25</td>\n",
       "      <td>67.92641</td>\n",
       "      <td>8.48886</td>\n",
       "      <td>5.65163</td>\n",
       "      <td>-59.43755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>KO</td>\n",
       "      <td>1998</td>\n",
       "      <td>1999-03-29</td>\n",
       "      <td>237.30348</td>\n",
       "      <td>179.91483</td>\n",
       "      <td>281.86254</td>\n",
       "      <td>-57.38865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015-02-24</td>\n",
       "      <td>334.22080</td>\n",
       "      <td>277.57445</td>\n",
       "      <td>310.70308</td>\n",
       "      <td>-56.64635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>IBM</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011-02-22</td>\n",
       "      <td>249.40784</td>\n",
       "      <td>194.53687</td>\n",
       "      <td>211.32738</td>\n",
       "      <td>-54.87097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>AGN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>112.58375</td>\n",
       "      <td>58.26221</td>\n",
       "      <td>45.78935</td>\n",
       "      <td>-54.32154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>KO</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>208.17547</td>\n",
       "      <td>154.18638</td>\n",
       "      <td>205.22608</td>\n",
       "      <td>-53.98909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol  calendarYear  filingDate      real  predicted  previousMarketCap  \\\n",
       "3194  GOOGL          2017  2018-02-06 823.17064  316.05172          644.27240   \n",
       "3181   GOOG          2017  2018-02-06 756.45198  320.13676          578.54152   \n",
       "1826   CSCO          2000  2000-09-29 640.96695  237.47861          326.03867   \n",
       "7794    XOM          2013  2014-02-26 488.00373  225.88919          478.35440   \n",
       "7793    XOM          2012  2012-12-31 478.35440  228.62606          499.72205   \n",
       "2771     FB          2017  2018-02-01 612.07527  370.93908          440.98280   \n",
       "7792    XOM          2011  2012-02-24 499.72205  263.45634          528.47053   \n",
       "339     AIG          2000  2000-12-31 364.13380  144.68086          248.23655   \n",
       "3066     GE          1997  1997-12-31 389.20414  182.12229          250.48968   \n",
       "4952   MSFT          2000  2000-09-28 504.30292  309.31759          749.62339   \n",
       "3072     GE          2003  2004-03-01 444.01120  255.74898          350.66415   \n",
       "7780    XOM          1999  1999-12-31 432.02958  247.00583          408.81038   \n",
       "3731   INTC          2001  2002-03-13 321.78971  155.28778          284.13555   \n",
       "3076     GE          2007  2008-02-20 424.14577  258.06713          455.01546   \n",
       "4967   MSFT          2015  2015-07-31 435.72527  273.97063          426.64532   \n",
       "6737      T          2006  2007-02-26 301.57010  155.27219          145.59525   \n",
       "4966   MSFT          2014  2014-07-31 426.64532  286.19073          322.05853   \n",
       "4955   MSFT          2003  2003-09-05 436.79820  300.41615          378.67650   \n",
       "7622    WMT          2004  2004-01-31 338.81402  202.61154          300.77608   \n",
       "875     BAC          2006  2006-12-31 320.87523  197.23433          254.69374   \n",
       "7799    XOM          2018  2019-02-27 367.80671  250.78715          361.04152   \n",
       "7636    WMT          2018  2018-03-30 285.94380  175.08838          246.22943   \n",
       "7290      V          2018  2018-11-16 344.20149  234.13817          291.87830   \n",
       "2003    CVX          2016  2017-02-23 238.62691  129.93909          184.75681   \n",
       "1189      C          2009  2010-02-26 126.32043   20.36587           10.81618   \n",
       "7621    WMT          2003  2003-01-31 300.77608  198.54078          300.77608   \n",
       "5712    PFE          1999  1999-12-31 311.83217  211.86300          397.42362   \n",
       "7541    WFC          2009  2010-02-26 183.61238   83.75846           60.09221   \n",
       "863      BA          2017  2018-02-12 230.80512  132.73587          117.66781   \n",
       "4880    MRK          1998  1998-12-31 277.38173  179.53987          249.18366   \n",
       "7160    UNH          2017  2018-02-13 248.58807  152.65083          176.65271   \n",
       "5766     PG          2013  2013-08-08 285.00460  190.93958          234.05602   \n",
       "3733   INTC          2003  2004-02-23 275.29992  183.69287          164.89576   \n",
       "2769     FB          2015  2016-01-28 344.48681  259.58671          249.43595   \n",
       "4086    KDP          2017  2018-02-14 101.78178   19.84647           19.58540   \n",
       "54     ABBV          2017  2018-02-16 206.45937  126.65237          111.57360   \n",
       "7432     VZ          1999  1999-12-31 227.31811  148.87430          216.13538   \n",
       "3414     HD          2018  2018-03-22 226.42715  155.87431          200.18051   \n",
       "3079     GE          2010  2011-02-25 261.60994  192.33677          207.97261   \n",
       "7062    TXN          1999  1999-12-31 133.33469   65.64159           55.09022   \n",
       "7447     VZ          2014  2015-02-23 235.72019  172.09517          190.55209   \n",
       "4177    KMI          2014  2015-02-23 103.58548   40.69058           39.09912   \n",
       "7430     VZ          1997  1997-12-31 172.61872  111.10735          118.52306   \n",
       "3661    IBM          2011  2012-02-28 284.15342  224.35928          249.40784   \n",
       "2745      F          2009  2010-02-25  67.92641    8.48886            5.65163   \n",
       "4192     KO          1998  1999-03-29 237.30348  179.91483          281.86254   \n",
       "3977    JNJ          2014  2015-02-24 334.22080  277.57445          310.70308   \n",
       "3660    IBM          2010  2011-02-22 249.40784  194.53687          211.32738   \n",
       "330     AGN          2014  2015-02-18 112.58375   58.26221           45.78935   \n",
       "4211     KO          2017  2018-02-23 208.17547  154.18638          205.22608   \n",
       "\n",
       "          error  \n",
       "3194 -507.11892  \n",
       "3181 -436.31522  \n",
       "1826 -403.48835  \n",
       "7794 -262.11453  \n",
       "7793 -249.72835  \n",
       "2771 -241.13618  \n",
       "7792 -236.26572  \n",
       "339  -219.45294  \n",
       "3066 -207.08184  \n",
       "4952 -194.98533  \n",
       "3072 -188.26222  \n",
       "7780 -185.02376  \n",
       "3731 -166.50193  \n",
       "3076 -166.07864  \n",
       "4967 -161.75464  \n",
       "6737 -146.29791  \n",
       "4966 -140.45459  \n",
       "4955 -136.38205  \n",
       "7622 -136.20249  \n",
       "875  -123.64090  \n",
       "7799 -117.01957  \n",
       "7636 -110.85542  \n",
       "7290 -110.06332  \n",
       "2003 -108.68782  \n",
       "1189 -105.95456  \n",
       "7621 -102.23530  \n",
       "5712  -99.96917  \n",
       "7541  -99.85392  \n",
       "863   -98.06926  \n",
       "4880  -97.84187  \n",
       "7160  -95.93724  \n",
       "5766  -94.06502  \n",
       "3733  -91.60705  \n",
       "2769  -84.90010  \n",
       "4086  -81.93531  \n",
       "54    -79.80699  \n",
       "7432  -78.44381  \n",
       "3414  -70.55284  \n",
       "3079  -69.27317  \n",
       "7062  -67.69310  \n",
       "7447  -63.62502  \n",
       "4177  -62.89490  \n",
       "7430  -61.51137  \n",
       "3661  -59.79413  \n",
       "2745  -59.43755  \n",
       "4192  -57.38865  \n",
       "3977  -56.64635  \n",
       "3660  -54.87097  \n",
       "330   -54.32154  \n",
       "4211  -53.98909  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.sort_values(by='error').head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna Experimantal API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpala\\AppData\\Local\\Temp\\ipykernel_3184\\1622451402.py:12: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  ('optuna', optuna.integration.OptunaSearchCV(net, param_distributions=net_params, scoring=mse_scorer, n_trials=200, verbose=1)),\n",
      "\u001b[32m[I 2022-04-17 12:48:17,785]\u001b[0m A new study created in memory with name: no-name-9b050571-cc4f-4f18-af59-52f5ad2b5bc4\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:17,787]\u001b[0m Searching the best hyperparameters using 6023 samples...\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:17,878]\u001b[0m Trial 0 finished with value: -3572.1511023244593 and parameters: {'alpha': 0.9983602815762588, 'l1_ratio': 0.0003397504845651885}. Best is trial 0 with value: -3572.1511023244593.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:18,456]\u001b[0m Trial 1 finished with value: -1395.5205985016005 and parameters: {'alpha': 0.003931969950844832, 'l1_ratio': 1.3929097884875017e-05}. Best is trial 1 with value: -1395.5205985016005.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:18,522]\u001b[0m Trial 2 finished with value: -4971.917848739251 and parameters: {'alpha': 2.637365293074038, 'l1_ratio': 0.007305044948091851}. Best is trial 1 with value: -1395.5205985016005.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:18,702]\u001b[0m Trial 3 finished with value: -1500.1689369370051 and parameters: {'alpha': 0.0359594480583442, 'l1_ratio': 0.00016506836966354547}. Best is trial 1 with value: -1395.5205985016005.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:19,050]\u001b[0m Trial 4 finished with value: -1383.573659233887 and parameters: {'alpha': 8.562368839590886e-05, 'l1_ratio': 0.27915394050270254}. Best is trial 4 with value: -1383.573659233887.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:19,145]\u001b[0m Trial 5 finished with value: -1513.174060505215 and parameters: {'alpha': 0.013094975151733088, 'l1_ratio': 0.6398577372524095}. Best is trial 4 with value: -1383.573659233887.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:19,214]\u001b[0m Trial 6 finished with value: -6533.2257069426105 and parameters: {'alpha': 731.9923052695839, 'l1_ratio': 0.0024644501361679636}. Best is trial 4 with value: -1383.573659233887.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:19,272]\u001b[0m Trial 7 finished with value: -6533.2257069426105 and parameters: {'alpha': 12.289437588526136, 'l1_ratio': 0.5200812604436763}. Best is trial 4 with value: -1383.573659233887.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:19,355]\u001b[0m Trial 8 finished with value: -3853.044170806461 and parameters: {'alpha': 1.2177136549169825, 'l1_ratio': 0.000910593698229785}. Best is trial 4 with value: -1383.573659233887.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:19,587]\u001b[0m Trial 9 finished with value: -1392.5804204940646 and parameters: {'alpha': 0.0016409924861899225, 'l1_ratio': 0.1912361015610267}. Best is trial 4 with value: -1383.573659233887.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:20,178]\u001b[0m Trial 10 finished with value: -1383.037405614094 and parameters: {'alpha': 1.2386364873317637e-05, 'l1_ratio': 0.031812106027240376}. Best is trial 10 with value: -1383.037405614094.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:20,747]\u001b[0m Trial 11 finished with value: -1383.0331605453844 and parameters: {'alpha': 1.0923048791718975e-05, 'l1_ratio': 0.03867880883271218}. Best is trial 11 with value: -1383.0331605453844.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:21,337]\u001b[0m Trial 12 finished with value: -1383.0335444949937 and parameters: {'alpha': 1.1595911357653162e-05, 'l1_ratio': 0.024941057643162075}. Best is trial 11 with value: -1383.0331605453844.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:21,804]\u001b[0m Trial 13 finished with value: -1383.419726923236 and parameters: {'alpha': 0.00012062948932985078, 'l1_ratio': 0.029116924077064395}. Best is trial 11 with value: -1383.0331605453844.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:21,877]\u001b[0m Trial 14 finished with value: -6533.2257069426105 and parameters: {'alpha': 56857.55430850187, 'l1_ratio': 0.03868327433735171}. Best is trial 11 with value: -1383.0331605453844.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:22,539]\u001b[0m Trial 15 finished with value: -1383.0262183362365 and parameters: {'alpha': 1.0167697655542448e-05, 'l1_ratio': 0.007182614186605392}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:23,044]\u001b[0m Trial 16 finished with value: -1384.2265558769338 and parameters: {'alpha': 0.0003829945259521497, 'l1_ratio': 0.004758241963391226}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:23,135]\u001b[0m Trial 17 finished with value: -1903.1759046115465 and parameters: {'alpha': 0.12642145827680876, 'l1_ratio': 0.08660624458254429}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:23,207]\u001b[0m Trial 18 finished with value: -6524.291656711195 and parameters: {'alpha': 84.24097079641511, 'l1_ratio': 0.009127064144269097}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:23,763]\u001b[0m Trial 19 finished with value: -1384.8005479149222 and parameters: {'alpha': 0.0005694069003859097, 'l1_ratio': 0.0010973518598629739}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:24,588]\u001b[0m Trial 20 finished with value: -1383.192889778808 and parameters: {'alpha': 6.328179594556057e-05, 'l1_ratio': 5.1210798030101195e-05}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:25,177]\u001b[0m Trial 21 finished with value: -1383.0468582657115 and parameters: {'alpha': 1.5512568562126897e-05, 'l1_ratio': 0.0233761528515953}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:25,664]\u001b[0m Trial 22 finished with value: -1383.0688410371076 and parameters: {'alpha': 1.641485040644987e-05, 'l1_ratio': 0.1114550449609533}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:26,118]\u001b[0m Trial 23 finished with value: -1384.1469868225831 and parameters: {'alpha': 0.00034691409876092254, 'l1_ratio': 0.012849738905072508}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:26,484]\u001b[0m Trial 24 finished with value: -1394.1310098143817 and parameters: {'alpha': 0.0034444271105164162, 'l1_ratio': 0.0033390064017217802}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:27,019]\u001b[0m Trial 25 finished with value: -1383.0421929516588 and parameters: {'alpha': 1.1966260157646067e-05, 'l1_ratio': 0.07208649131476351}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:27,637]\u001b[0m Trial 26 finished with value: -1383.313117202768 and parameters: {'alpha': 0.00010078643351998394, 'l1_ratio': 0.0014477725419060697}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:27,768]\u001b[0m Trial 27 finished with value: -1627.8504123685495 and parameters: {'alpha': 0.07103672263068846, 'l1_ratio': 0.015590530762644198}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:28,316]\u001b[0m Trial 28 finished with value: -1386.1620991330549 and parameters: {'alpha': 0.0009999292675717155, 'l1_ratio': 0.0004272896178449019}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:28,394]\u001b[0m Trial 29 finished with value: -2418.0906408397104 and parameters: {'alpha': 0.2861484672781733, 'l1_ratio': 0.06383280929450677}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:28,503]\u001b[0m Trial 30 finished with value: -1468.791713733478 and parameters: {'alpha': 0.013931721361310347, 'l1_ratio': 0.22769892227824212}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:29,125]\u001b[0m Trial 31 finished with value: -1383.0310039235933 and parameters: {'alpha': 1.1035789570440037e-05, 'l1_ratio': 0.02083351756366761}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:29,712]\u001b[0m Trial 32 finished with value: -1383.1514963433108 and parameters: {'alpha': 4.9142955291767374e-05, 'l1_ratio': 0.005088592009226547}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:30,215]\u001b[0m Trial 33 finished with value: -1383.538957082043 and parameters: {'alpha': 0.00016424831280152945, 'l1_ratio': 0.012765831331910147}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:30,712]\u001b[0m Trial 34 finished with value: -1383.1245165929267 and parameters: {'alpha': 3.519839862766065e-05, 'l1_ratio': 0.04416165599436678}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:31,012]\u001b[0m Trial 35 finished with value: -1395.8329596046847 and parameters: {'alpha': 0.0038659157517123032, 'l1_ratio': 0.00885651520260571}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:32,010]\u001b[0m Trial 36 finished with value: -1383.0295630249693 and parameters: {'alpha': 1.1529471963577385e-05, 'l1_ratio': 1.0141626853231027e-05}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:32,868]\u001b[0m Trial 37 finished with value: -1383.6983980838822 and parameters: {'alpha': 0.00022340177620401884, 'l1_ratio': 1.0442850194380036e-05}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:33,728]\u001b[0m Trial 38 finished with value: -1383.156624080801 and parameters: {'alpha': 5.1796099124796326e-05, 'l1_ratio': 2.9578211610555275e-05}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:33,800]\u001b[0m Trial 39 finished with value: -6532.446210019223 and parameters: {'alpha': 5543.229025044564, 'l1_ratio': 2.3891436482698393e-05}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:33,879]\u001b[0m Trial 40 finished with value: -5793.111315725246 and parameters: {'alpha': 7.053741219525264, 'l1_ratio': 0.00020884448131484212}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:34,602]\u001b[0m Trial 41 finished with value: -1383.0275467172528 and parameters: {'alpha': 1.0796205477393663e-05, 'l1_ratio': 0.0021185102076243674}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:35,420]\u001b[0m Trial 42 finished with value: -1383.1013345376903 and parameters: {'alpha': 3.4266927831299394e-05, 'l1_ratio': 8.803473153508689e-05}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:35,915]\u001b[0m Trial 43 finished with value: -1386.7911219061032 and parameters: {'alpha': 0.0011893855904443723, 'l1_ratio': 0.0021315054252560393}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:36,295]\u001b[0m Trial 44 finished with value: -1383.4617087834517 and parameters: {'alpha': 2.9590805406356445e-05, 'l1_ratio': 0.9782108987203033}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:37,153]\u001b[0m Trial 45 finished with value: -1383.0274301018549 and parameters: {'alpha': 1.081741844879316e-05, 'l1_ratio': 0.0008141107001813555}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:37,880]\u001b[0m Trial 46 finished with value: -1383.4390143831486 and parameters: {'alpha': 0.00014093183812781036, 'l1_ratio': 0.000584184292516612}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:38,228]\u001b[0m Trial 47 finished with value: -1430.4793198069308 and parameters: {'alpha': 0.014677477193554103, 'l1_ratio': 0.00016082745797398808}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:38,888]\u001b[0m Trial 48 finished with value: -1384.3005073490644 and parameters: {'alpha': 0.00041266422378845617, 'l1_ratio': 0.0007408269309484068}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:39,624]\u001b[0m Trial 49 finished with value: -1383.087182383619 and parameters: {'alpha': 2.9530694555246098e-05, 'l1_ratio': 0.0021550702449000605}. Best is trial 15 with value: -1383.0262183362365.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:40,351]\u001b[0m Trial 50 finished with value: -1383.0260985629745 and parameters: {'alpha': 1.0197842462853144e-05, 'l1_ratio': 0.005546134756801408}. Best is trial 50 with value: -1383.0260985629745.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:40,964]\u001b[0m Trial 51 finished with value: -1383.2751255876658 and parameters: {'alpha': 8.771908043831911e-05, 'l1_ratio': 0.004504159379382434}. Best is trial 50 with value: -1383.0260985629745.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:41,693]\u001b[0m Trial 52 finished with value: -1383.0269002867688 and parameters: {'alpha': 1.04155161920222e-05, 'l1_ratio': 0.0062769981870610435}. Best is trial 50 with value: -1383.0260985629745.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:42,387]\u001b[0m Trial 53 finished with value: -1383.0881998085083 and parameters: {'alpha': 2.933609195533184e-05, 'l1_ratio': 0.0064323602100293375}. Best is trial 50 with value: -1383.0260985629745.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:42,464]\u001b[0m Trial 54 finished with value: -6492.120160781991 and parameters: {'alpha': 81.01938086218487, 'l1_ratio': 0.0028593012219418033}. Best is trial 50 with value: -1383.0260985629745.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:43,151]\u001b[0m Trial 55 finished with value: -1383.2510792202834 and parameters: {'alpha': 8.121906525192472e-05, 'l1_ratio': 0.0015325563509850024}. Best is trial 50 with value: -1383.0260985629745.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:43,707]\u001b[0m Trial 56 finished with value: -1383.6113219817973 and parameters: {'alpha': 0.00018935063020846248, 'l1_ratio': 0.0082821462609059}. Best is trial 50 with value: -1383.0260985629745.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:44,622]\u001b[0m Trial 57 finished with value: -1383.0255228639066 and parameters: {'alpha': 1.0237802853068885e-05, 'l1_ratio': 0.0002703716060154129}. Best is trial 57 with value: -1383.0255228639066.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:45,301]\u001b[0m Trial 58 finished with value: -1384.846067356119 and parameters: {'alpha': 0.0005851711793544907, 'l1_ratio': 0.0004977695616966733}. Best is trial 57 with value: -1383.0255228639066.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:46,020]\u001b[0m Trial 59 finished with value: -1383.0651720289202 and parameters: {'alpha': 2.249569722931263e-05, 'l1_ratio': 0.0034566577289973205}. Best is trial 57 with value: -1383.0255228639066.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:46,939]\u001b[0m Trial 60 finished with value: -1383.0254101117332 and parameters: {'alpha': 1.0202995317624284e-05, 'l1_ratio': 0.00024920000518202526}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:47,818]\u001b[0m Trial 61 finished with value: -1383.0802663890297 and parameters: {'alpha': 2.7587065970319914e-05, 'l1_ratio': 0.00012867140666822044}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:48,618]\u001b[0m Trial 62 finished with value: -1383.1605636946078 and parameters: {'alpha': 5.297618996118663e-05, 'l1_ratio': 0.00034117637334721393}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:49,465]\u001b[0m Trial 63 finished with value: -1383.026515523195 and parameters: {'alpha': 1.0523866635190312e-05, 'l1_ratio': 0.0009205091232961467}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:50,259]\u001b[0m Trial 64 finished with value: -1383.258393076733 and parameters: {'alpha': 8.395540670143165e-05, 'l1_ratio': 0.0002767626734083936}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:50,911]\u001b[0m Trial 65 finished with value: -1383.7462840889693 and parameters: {'alpha': 0.00023762648748002938, 'l1_ratio': 0.0009603922251895836}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:51,699]\u001b[0m Trial 66 finished with value: -1383.056306220317 and parameters: {'alpha': 1.989153044808633e-05, 'l1_ratio': 0.001405044439774493}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:52,586]\u001b[0m Trial 67 finished with value: -1383.1928983382056 and parameters: {'alpha': 6.32705901226283e-05, 'l1_ratio': 0.00010440857134197904}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:53,431]\u001b[0m Trial 68 finished with value: -1383.0287978377044 and parameters: {'alpha': 1.1253104689306702e-05, 'l1_ratio': 0.0007370488108086462}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:53,962]\u001b[0m Trial 69 finished with value: -1389.8548810433215 and parameters: {'alpha': 0.00215838047065029, 'l1_ratio': 0.00044463735526140515}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:54,630]\u001b[0m Trial 70 finished with value: -1383.4169334681053 and parameters: {'alpha': 0.0001336172133310655, 'l1_ratio': 0.0011954464705852877}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:55,536]\u001b[0m Trial 71 finished with value: -1383.0264840034718 and parameters: {'alpha': 1.054324229049077e-05, 'l1_ratio': 0.0002450389460004874}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:56,466]\u001b[0m Trial 72 finished with value: -1383.0612633203066 and parameters: {'alpha': 2.1572785725976686e-05, 'l1_ratio': 6.288366312751072e-05}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:57,377]\u001b[0m Trial 73 finished with value: -1383.0264472695576 and parameters: {'alpha': 1.0531931688715401e-05, 'l1_ratio': 0.00023762244218529307}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:58,210]\u001b[0m Trial 74 finished with value: -1383.161525882487 and parameters: {'alpha': 5.3320946206323876e-05, 'l1_ratio': 0.0001584628612406793}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:59,015]\u001b[0m Trial 75 finished with value: -1383.057008911937 and parameters: {'alpha': 2.021126708622268e-05, 'l1_ratio': 0.00022243435795843577}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:48:59,618]\u001b[0m Trial 76 finished with value: -1384.9187591592529 and parameters: {'alpha': 0.0006085510371261574, 'l1_ratio': 0.00031396430365905425}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:00,185]\u001b[0m Trial 77 finished with value: -1383.1284399088754 and parameters: {'alpha': 4.074520838429455e-05, 'l1_ratio': 0.012609305030008719}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:01,073]\u001b[0m Trial 78 finished with value: -1383.0532159580912 and parameters: {'alpha': 1.9022364964540802e-05, 'l1_ratio': 6.629783601070334e-05}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:01,156]\u001b[0m Trial 79 finished with value: -3686.7670311681045 and parameters: {'alpha': 1.0404100739131552, 'l1_ratio': 0.006332703528344937}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:01,942]\u001b[0m Trial 80 finished with value: -1383.6917405815016 and parameters: {'alpha': 0.0002212731768872548, 'l1_ratio': 3.332985672184162e-05}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:02,760]\u001b[0m Trial 81 finished with value: -1383.0426824662777 and parameters: {'alpha': 1.567429569183419e-05, 'l1_ratio': 0.00022168092968116506}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:03,555]\u001b[0m Trial 82 finished with value: -1383.0256697220148 and parameters: {'alpha': 1.0266691358371646e-05, 'l1_ratio': 0.0006855336361519342}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:04,347]\u001b[0m Trial 83 finished with value: -1383.0257341980823 and parameters: {'alpha': 1.0290262481362146e-05, 'l1_ratio': 0.0006103634563172678}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:05,023]\u001b[0m Trial 84 finished with value: -1383.3092857800902 and parameters: {'alpha': 9.995036666924112e-05, 'l1_ratio': 0.000546368370514395}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:05,797]\u001b[0m Trial 85 finished with value: -1383.1242549827211 and parameters: {'alpha': 4.1488354573236643e-05, 'l1_ratio': 0.0003233839762891195}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:06,599]\u001b[0m Trial 86 finished with value: -1383.0467529213888 and parameters: {'alpha': 1.6951809785999545e-05, 'l1_ratio': 0.0003867421175235275}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:07,379]\u001b[0m Trial 87 finished with value: -1383.1282829532443 and parameters: {'alpha': 4.2777934314109506e-05, 'l1_ratio': 0.0002402755565286952}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:07,448]\u001b[0m Trial 88 finished with value: -6533.2257069426105 and parameters: {'alpha': 18366.912207319627, 'l1_ratio': 0.0006373736548608641}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:08,480]\u001b[0m Trial 89 finished with value: -1383.0263747604545 and parameters: {'alpha': 1.0514169979266649e-05, 'l1_ratio': 0.00011795191377112282}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:08,616]\u001b[0m Trial 90 finished with value: -2367.4146055647548 and parameters: {'alpha': 0.3443285658409236, 'l1_ratio': 0.00014414175228321763}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:09,533]\u001b[0m Trial 91 finished with value: -1383.075168042044 and parameters: {'alpha': 2.5972861352819675e-05, 'l1_ratio': 0.00012009305747003751}. Best is trial 60 with value: -1383.0254101117332.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:10,594]\u001b[0m Trial 92 finished with value: -1383.0249140368637 and parameters: {'alpha': 1.005299444334548e-05, 'l1_ratio': 7.846533154875004e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:11,479]\u001b[0m Trial 93 finished with value: -1383.2087827062687 and parameters: {'alpha': 6.831100341299041e-05, 'l1_ratio': 7.248970581966899e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:12,480]\u001b[0m Trial 94 finished with value: -1383.0461372054046 and parameters: {'alpha': 1.678107929085282e-05, 'l1_ratio': 3.8590984931995014e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:13,432]\u001b[0m Trial 95 finished with value: -1383.0877042150917 and parameters: {'alpha': 2.995676554750623e-05, 'l1_ratio': 1.993712358523732e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:14,423]\u001b[0m Trial 96 finished with value: -1383.0253221537587 and parameters: {'alpha': 1.0183742252047322e-05, 'l1_ratio': 4.475190062575238e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:15,269]\u001b[0m Trial 97 finished with value: -1383.3545674989523 and parameters: {'alpha': 0.00011450209495764947, 'l1_ratio': 4.2024062259952e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:16,132]\u001b[0m Trial 98 finished with value: -1383.1221181092785 and parameters: {'alpha': 4.085155469078628e-05, 'l1_ratio': 8.90614237258572e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:16,218]\u001b[0m Trial 99 finished with value: -6476.0515737125 and parameters: {'alpha': 102.70020359559788, 'l1_ratio': 5.2668180764073616e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:17,070]\u001b[0m Trial 100 finished with value: -1384.0897274297083 and parameters: {'alpha': 0.0003472361456947948, 'l1_ratio': 1.6103325268485796e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:17,989]\u001b[0m Trial 101 finished with value: -1383.0430671618053 and parameters: {'alpha': 1.580502608918062e-05, 'l1_ratio': 8.535401546866419e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:18,864]\u001b[0m Trial 102 finished with value: -1383.028373034717 and parameters: {'alpha': 1.114271098843907e-05, 'l1_ratio': 0.0002176022003386808}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:19,757]\u001b[0m Trial 103 finished with value: -1383.025376621339 and parameters: {'alpha': 1.0194630780393317e-05, 'l1_ratio': 0.0001959568718640075}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:20,612]\u001b[0m Trial 104 finished with value: -1383.0617565135865 and parameters: {'alpha': 2.1719363528213127e-05, 'l1_ratio': 0.00017101935069746023}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:21,392]\u001b[0m Trial 105 finished with value: -1383.212186448357 and parameters: {'alpha': 6.937756355025725e-05, 'l1_ratio': 0.00011328363317459201}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:22,065]\u001b[0m Trial 106 finished with value: -1383.0846256141735 and parameters: {'alpha': 2.8524965985179023e-05, 'l1_ratio': 0.0038855909850132844}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:22,871]\u001b[0m Trial 107 finished with value: -1383.049212463247 and parameters: {'alpha': 1.7725003550830363e-05, 'l1_ratio': 0.00045763725769565057}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:23,722]\u001b[0m Trial 108 finished with value: -1383.1147170484535 and parameters: {'alpha': 3.849554046705279e-05, 'l1_ratio': 0.00015941638462761796}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:24,585]\u001b[0m Trial 109 finished with value: -1383.1852126983174 and parameters: {'alpha': 6.085028165359483e-05, 'l1_ratio': 4.800517938474004e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:25,345]\u001b[0m Trial 110 finished with value: -1383.3845132813615 and parameters: {'alpha': 0.0001239175714842026, 'l1_ratio': 0.00017729349224677047}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:26,216]\u001b[0m Trial 111 finished with value: -1383.0292029772972 and parameters: {'alpha': 1.1403935494921045e-05, 'l1_ratio': 0.00025206783525179337}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:27,079]\u001b[0m Trial 112 finished with value: -1383.0266868307704 and parameters: {'alpha': 1.0602457949509444e-05, 'l1_ratio': 0.00035941652462196885}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:27,989]\u001b[0m Trial 113 finished with value: -1383.0253318618443 and parameters: {'alpha': 1.018442043265245e-05, 'l1_ratio': 0.00010170167385146892}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:28,588]\u001b[0m Trial 114 finished with value: -1383.0757199146428 and parameters: {'alpha': 2.436204082140599e-05, 'l1_ratio': 0.017851224756849082}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:29,499]\u001b[0m Trial 115 finished with value: -1383.0499438290803 and parameters: {'alpha': 1.7983024852759902e-05, 'l1_ratio': 9.897446337736719e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:30,611]\u001b[0m Trial 116 finished with value: -1383.091970526526 and parameters: {'alpha': 3.130399316603042e-05, 'l1_ratio': 5.7719892817661e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:31,612]\u001b[0m Trial 117 finished with value: -1383.0421054748895 and parameters: {'alpha': 1.550094156028815e-05, 'l1_ratio': 7.524949615526055e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:31,703]\u001b[0m Trial 118 finished with value: -4741.195090350241 and parameters: {'alpha': 2.3557171417031793, 'l1_ratio': 0.0003046531439158956}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:31,829]\u001b[0m Trial 119 finished with value: -1511.8833142037333 and parameters: {'alpha': 0.037807141671151845, 'l1_ratio': 0.010194342375028132}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:32,838]\u001b[0m Trial 120 finished with value: -1383.0249769862503 and parameters: {'alpha': 1.0074960466529408e-05, 'l1_ratio': 3.000340725636894e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:33,802]\u001b[0m Trial 121 finished with value: -1383.043381180748 and parameters: {'alpha': 1.5908302787727787e-05, 'l1_ratio': 2.8005044312953782e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:34,639]\u001b[0m Trial 122 finished with value: -1383.1253278814318 and parameters: {'alpha': 4.1861493108004365e-05, 'l1_ratio': 0.00012939667213150924}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:35,371]\u001b[0m Trial 123 finished with value: -1383.0256317179733 and parameters: {'alpha': 1.0170729754633869e-05, 'l1_ratio': 0.00268696841687582}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:36,313]\u001b[0m Trial 124 finished with value: -1383.0706188343959 and parameters: {'alpha': 2.454129760426785e-05, 'l1_ratio': 2.481386607088775e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:36,923]\u001b[0m Trial 125 finished with value: -1383.178506970427 and parameters: {'alpha': 5.763205557683738e-05, 'l1_ratio': 0.004636806864197383}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:37,638]\u001b[0m Trial 126 finished with value: -1383.068596760423 and parameters: {'alpha': 2.3712107020329362e-05, 'l1_ratio': 0.0019452903036241728}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:38,668]\u001b[0m Trial 127 finished with value: -1383.026459962809 and parameters: {'alpha': 1.0545471808969392e-05, 'l1_ratio': 1.912709339302044e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:39,310]\u001b[0m Trial 128 finished with value: -1383.2729482168331 and parameters: {'alpha': 8.768088634261882e-05, 'l1_ratio': 0.0027095171051024535}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:40,219]\u001b[0m Trial 129 finished with value: -1383.1117032447034 and parameters: {'alpha': 3.7559596245957884e-05, 'l1_ratio': 3.942641777577266e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:40,469]\u001b[0m Trial 130 finished with value: -1411.5044982410905 and parameters: {'alpha': 0.00855533680362414, 'l1_ratio': 0.007552078578254574}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:41,277]\u001b[0m Trial 131 finished with value: -1383.0433651326357 and parameters: {'alpha': 1.5861024884022722e-05, 'l1_ratio': 0.0006714736370668338}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:42,174]\u001b[0m Trial 132 finished with value: -1383.0278042695795 and parameters: {'alpha': 1.0964240067000213e-05, 'l1_ratio': 0.0001809155165480794}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:43,109]\u001b[0m Trial 133 finished with value: -1383.0251542476544 and parameters: {'alpha': 1.012799366167469e-05, 'l1_ratio': 0.00010526432199386084}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:44,004]\u001b[0m Trial 134 finished with value: -1383.0668439713966 and parameters: {'alpha': 2.3337810893654924e-05, 'l1_ratio': 9.835679563757269e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:44,897]\u001b[0m Trial 135 finished with value: -1383.0478299178872 and parameters: {'alpha': 1.7310620492391875e-05, 'l1_ratio': 0.00013543993834013772}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:45,889]\u001b[0m Trial 136 finished with value: -1383.0255277073456 and parameters: {'alpha': 1.0248769654419013e-05, 'l1_ratio': 4.7566322752783706e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:46,764]\u001b[0m Trial 137 finished with value: -1383.101101923738 and parameters: {'alpha': 3.419618411404688e-05, 'l1_ratio': 6.712869862329025e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:47,627]\u001b[0m Trial 138 finished with value: -1383.1389255942784 and parameters: {'alpha': 4.618322401956322e-05, 'l1_ratio': 5.336304281834675e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:48,582]\u001b[0m Trial 139 finished with value: -1383.0461242523568 and parameters: {'alpha': 1.6777222374417585e-05, 'l1_ratio': 3.501162942815222e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:49,542]\u001b[0m Trial 140 finished with value: -1383.025138644347 and parameters: {'alpha': 1.0123905091658553e-05, 'l1_ratio': 8.477861944167831e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:50,438]\u001b[0m Trial 141 finished with value: -1383.0688090582053 and parameters: {'alpha': 2.3962072681471046e-05, 'l1_ratio': 8.176410394243724e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:51,365]\u001b[0m Trial 142 finished with value: -1383.045011601549 and parameters: {'alpha': 1.642385798589503e-05, 'l1_ratio': 4.56926219530895e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:52,352]\u001b[0m Trial 143 finished with value: -1383.0272478484262 and parameters: {'alpha': 1.0794678435150126e-05, 'l1_ratio': 3.09680819986586e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:53,248]\u001b[0m Trial 144 finished with value: -1383.0906852039293 and parameters: {'alpha': 3.089501483650911e-05, 'l1_ratio': 7.092823073222049e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:54,102]\u001b[0m Trial 145 finished with value: -1383.16515046985 and parameters: {'alpha': 5.4491049205989256e-05, 'l1_ratio': 5.994159639256133e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:55,120]\u001b[0m Trial 146 finished with value: -1383.0420597860025 and parameters: {'alpha': 1.5490414411203804e-05, 'l1_ratio': 1.3569141206964765e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:55,846]\u001b[0m Trial 147 finished with value: -1383.0886650650843 and parameters: {'alpha': 3.0102180068100995e-05, 'l1_ratio': 0.0012979730924392587}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:56,771]\u001b[0m Trial 148 finished with value: -1383.0254770188512 and parameters: {'alpha': 1.0230529888602421e-05, 'l1_ratio': 9.902053763850874e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:57,684]\u001b[0m Trial 149 finished with value: -1383.0269812898218 and parameters: {'alpha': 1.070687040980006e-05, 'l1_ratio': 0.00010598167096624548}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:58,576]\u001b[0m Trial 150 finished with value: -1383.0256118706634 and parameters: {'alpha': 1.0269121459128168e-05, 'l1_ratio': 0.0001964765490412192}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:49:59,458]\u001b[0m Trial 151 finished with value: -1383.0254559811085 and parameters: {'alpha': 1.0219368479539705e-05, 'l1_ratio': 0.00020539590408996035}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:00,307]\u001b[0m Trial 152 finished with value: -1383.0577626233255 and parameters: {'alpha': 2.045163437853034e-05, 'l1_ratio': 0.00020255055391810736}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:01,184]\u001b[0m Trial 153 finished with value: -1383.0438017537679 and parameters: {'alpha': 1.603403265853539e-05, 'l1_ratio': 0.00014218014357651192}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:02,043]\u001b[0m Trial 154 finished with value: -1383.0258844096952 and parameters: {'alpha': 1.0345511653799305e-05, 'l1_ratio': 0.0004287184059500911}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:02,117]\u001b[0m Trial 155 finished with value: -6531.333743646987 and parameters: {'alpha': 1302.8668596636642, 'l1_ratio': 0.0003047060624947049}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:03,101]\u001b[0m Trial 156 finished with value: -1383.0251100367013 and parameters: {'alpha': 1.0114742311370572e-05, 'l1_ratio': 8.711910227655631e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:04,056]\u001b[0m Trial 157 finished with value: -1383.07096190852 and parameters: {'alpha': 2.4643798680188308e-05, 'l1_ratio': 8.594456318115873e-05}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:04,888]\u001b[0m Trial 158 finished with value: -1383.1433697552588 and parameters: {'alpha': 4.757895035888122e-05, 'l1_ratio': 0.00011650461618969773}. Best is trial 92 with value: -1383.0249140368637.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:05,799]\u001b[0m Trial 159 finished with value: -1383.024913245712 and parameters: {'alpha': 1.0048632434520116e-05, 'l1_ratio': 0.00017742565916799172}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:06,666]\u001b[0m Trial 160 finished with value: -1383.0488403054076 and parameters: {'alpha': 1.762802855173078e-05, 'l1_ratio': 0.00017229395652763044}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:07,552]\u001b[0m Trial 161 finished with value: -1383.0427050718888 and parameters: {'alpha': 1.568675083722148e-05, 'l1_ratio': 0.00013995072721141073}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:08,457]\u001b[0m Trial 162 finished with value: -1383.0758523672089 and parameters: {'alpha': 2.6192590970772494e-05, 'l1_ratio': 9.301223980246746e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:09,373]\u001b[0m Trial 163 finished with value: -1383.0259891440305 and parameters: {'alpha': 1.0388648726249653e-05, 'l1_ratio': 0.00019573986200840357}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:10,255]\u001b[0m Trial 164 finished with value: -1383.100006940466 and parameters: {'alpha': 3.385027123526858e-05, 'l1_ratio': 5.9658688288899166e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:11,094]\u001b[0m Trial 165 finished with value: -1383.0425880185899 and parameters: {'alpha': 1.564085644072744e-05, 'l1_ratio': 0.0002762534767508712}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:12,036]\u001b[0m Trial 166 finished with value: -1383.065804562864 and parameters: {'alpha': 2.3013351465866025e-05, 'l1_ratio': 4.717743895094311e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:12,873]\u001b[0m Trial 167 finished with value: -1383.2423524401272 and parameters: {'alpha': 7.893282797513075e-05, 'l1_ratio': 0.00011035596093975558}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:13,810]\u001b[0m Trial 168 finished with value: -1383.041282459269 and parameters: {'alpha': 1.5240070731486311e-05, 'l1_ratio': 7.633713725451488e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:14,710]\u001b[0m Trial 169 finished with value: -1383.0252942183156 and parameters: {'alpha': 1.0169706988587376e-05, 'l1_ratio': 0.0001679619417575626}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:15,619]\u001b[0m Trial 170 finished with value: -1383.0258934859025 and parameters: {'alpha': 1.0360084152971398e-05, 'l1_ratio': 0.00015526580818065513}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:16,487]\u001b[0m Trial 171 finished with value: -1383.0645213396074 and parameters: {'alpha': 2.259186012469351e-05, 'l1_ratio': 0.00020584391114946164}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:17,363]\u001b[0m Trial 172 finished with value: -1383.0253304051453 and parameters: {'alpha': 1.017729879904901e-05, 'l1_ratio': 0.00025999444412321855}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:17,434]\u001b[0m Trial 173 finished with value: -6533.2257069426105 and parameters: {'alpha': 17.946191882479493, 'l1_ratio': 0.11344605708915499}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:18,232]\u001b[0m Trial 174 finished with value: -1383.1004540539566 and parameters: {'alpha': 3.3963956499118225e-05, 'l1_ratio': 0.00025892935442665667}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:19,149]\u001b[0m Trial 175 finished with value: -1383.0253380239305 and parameters: {'alpha': 1.0185278492733005e-05, 'l1_ratio': 0.00012774098878005533}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:20,050]\u001b[0m Trial 176 finished with value: -1383.0438348576342 and parameters: {'alpha': 1.6045525383451882e-05, 'l1_ratio': 0.0001269895135744615}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:20,998]\u001b[0m Trial 177 finished with value: -1383.0252170652518 and parameters: {'alpha': 1.0148291062596364e-05, 'l1_ratio': 9.585605083737146e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:21,896]\u001b[0m Trial 178 finished with value: -1383.0628242507337 and parameters: {'alpha': 2.206409715698955e-05, 'l1_ratio': 9.941353955298097e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:22,838]\u001b[0m Trial 179 finished with value: -1383.1312265658346 and parameters: {'alpha': 4.3740089735680934e-05, 'l1_ratio': 7.345878814069566e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:23,818]\u001b[0m Trial 180 finished with value: -1383.0445975488503 and parameters: {'alpha': 1.6293126404120086e-05, 'l1_ratio': 3.838532130317766e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:24,760]\u001b[0m Trial 181 finished with value: -1383.0249457840323 and parameters: {'alpha': 1.0060655485106049e-05, 'l1_ratio': 0.0001361753739430882}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:25,671]\u001b[0m Trial 182 finished with value: -1383.0257361527583 and parameters: {'alpha': 1.0310607656983997e-05, 'l1_ratio': 0.00014666389238353783}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:26,612]\u001b[0m Trial 183 finished with value: -1383.047686296791 and parameters: {'alpha': 1.72679597869655e-05, 'l1_ratio': 9.56501805115371e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:27,551]\u001b[0m Trial 184 finished with value: -1383.0774894159651 and parameters: {'alpha': 2.6715792597403495e-05, 'l1_ratio': 5.211858716424752e-05}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:28,439]\u001b[0m Trial 185 finished with value: -1383.0469869767394 and parameters: {'alpha': 1.7044509312755776e-05, 'l1_ratio': 0.0001221650411307447}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:29,353]\u001b[0m Trial 186 finished with value: -1383.025473728155 and parameters: {'alpha': 1.0226520826482179e-05, 'l1_ratio': 0.00016915949316146476}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:30,181]\u001b[0m Trial 187 finished with value: -1383.0998204643263 and parameters: {'alpha': 3.377530730873401e-05, 'l1_ratio': 0.00017333933666590208}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:31,003]\u001b[0m Trial 188 finished with value: -1383.0452897415778 and parameters: {'alpha': 1.6489915274969674e-05, 'l1_ratio': 0.000369767859762752}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:31,961]\u001b[0m Trial 189 finished with value: -1383.0252022878688 and parameters: {'alpha': 1.0137317323428574e-05, 'l1_ratio': 0.00024596862248513755}. Best is trial 159 with value: -1383.024913245712.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:32,852]\u001b[0m Trial 190 finished with value: -1383.0248810646567 and parameters: {'alpha': 1.0039563214661087e-05, 'l1_ratio': 0.00015028635731491528}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:33,756]\u001b[0m Trial 191 finished with value: -1383.0420392466656 and parameters: {'alpha': 1.5475404337037417e-05, 'l1_ratio': 0.00014637013791617807}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:34,593]\u001b[0m Trial 192 finished with value: -1383.0703699110159 and parameters: {'alpha': 2.4440401071876055e-05, 'l1_ratio': 0.00024246847191253552}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:35,507]\u001b[0m Trial 193 finished with value: -1383.0410220043614 and parameters: {'alpha': 1.5155539837252306e-05, 'l1_ratio': 0.00010821233233032672}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:36,420]\u001b[0m Trial 194 finished with value: -1383.0261028402497 and parameters: {'alpha': 1.0425527897035394e-05, 'l1_ratio': 0.00017560872353040622}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:37,360]\u001b[0m Trial 195 finished with value: -1383.0681392325307 and parameters: {'alpha': 2.3749286191486866e-05, 'l1_ratio': 8.731059352010256e-05}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:38,326]\u001b[0m Trial 196 finished with value: -1383.0257618782834 and parameters: {'alpha': 1.0319309913216554e-05, 'l1_ratio': 0.00013377264857271292}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:39,197]\u001b[0m Trial 197 finished with value: -1383.1018850930404 and parameters: {'alpha': 3.4423779102170506e-05, 'l1_ratio': 0.00021154003495042656}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:40,178]\u001b[0m Trial 198 finished with value: -1383.0570674616208 and parameters: {'alpha': 2.024266813599634e-05, 'l1_ratio': 6.867644644262942e-05}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:41,060]\u001b[0m Trial 199 finished with value: -1383.1558311133397 and parameters: {'alpha': 5.152592206319443e-05, 'l1_ratio': 0.00011829380958764143}. Best is trial 190 with value: -1383.0248810646567.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:41,061]\u001b[0m Finished hyperparemeter search!\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:41,062]\u001b[0m Refitting the estimator using 6023 samples...\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:50:41,268]\u001b[0m Finished refitting! (elapsed time: 0.205 sec.)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1112.004942898849, 33.3467381148269)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ElasticNet()\n",
    "mse_scorer = make_scorer(custom_score, greater_is_better=False)\n",
    "net_params = {\n",
    "    'alpha' : optuna.distributions.LogUniformDistribution(1e-5, 1e5),\n",
    "    'l1_ratio' : optuna.distributions.LogUniformDistribution(1e-5, 1),\n",
    "\n",
    "}\n",
    "linear_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('feature_clipper', Windsorizer()),\n",
    "        ('normalizer', PowerTransformer()),\n",
    "        ('optuna', optuna.integration.OptunaSearchCV(net, param_distributions=net_params, scoring=mse_scorer, n_trials=200, verbose=1)),\n",
    "    ]\n",
    ")\n",
    "linear_pipe.fit(X_train,y_train)\n",
    "preds = linear_pipe.predict(X_test)\n",
    "mse = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds))\n",
    "mse , np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpala\\AppData\\Local\\Temp\\ipykernel_3184\\3654521277.py:11: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  ('optuna', optuna.integration.OptunaSearchCV(model, param_distributions=model_params, scoring=mse_scorer, timeout=300, verbose=1, n_trials=None)),\n",
      "\u001b[32m[I 2022-04-17 12:51:03,647]\u001b[0m A new study created in memory with name: no-name-5a63ac67-0a71-42b9-9bc7-ef8e2d197786\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:51:03,648]\u001b[0m Searching the best hyperparameters using 6023 samples...\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-04-17 12:51:16,406]\u001b[0m Trial 0 finished with value: -1443.1740769437981 and parameters: {'C': 3.6940975735031287}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-04-17 12:51:31,444]\u001b[0m Trial 1 finished with value: -1805.6882955814422 and parameters: {'C': 67.58493000758466}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-04-17 12:51:45,990]\u001b[0m Trial 2 finished with value: -1542.1125792011385 and parameters: {'C': 9.19644495111444}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-04-17 12:52:01,141]\u001b[0m Trial 3 finished with value: -1902.361528923289 and parameters: {'C': 27.817666961099203}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:52:02,793]\u001b[0m Trial 4 finished with value: -1462.602445287154 and parameters: {'C': 0.10859687943426088}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-04-17 12:52:04,762]\u001b[0m Trial 5 finished with value: -1461.5134873572138 and parameters: {'C': 0.13017284357505354}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-04-17 12:52:15,744]\u001b[0m Trial 6 finished with value: -1471.2038306589786 and parameters: {'C': 2.218279785023802}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-04-17 12:52:29,073]\u001b[0m Trial 7 finished with value: -1502.6688760792015 and parameters: {'C': 5.047992502194443}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 12:52:29,572]\u001b[0m Trial 8 finished with value: -1483.893898538045 and parameters: {'C': 0.026756901760446674}. Best is trial 0 with value: -1443.1740769437981.\u001b[0m\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fpala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fpala\\2022\\sp500\\src\\notebooks\\model_selection.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=2'>3</a>\u001b[0m model_params \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m : optuna\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mLogUniformDistribution(\u001b[39m1e-2\u001b[39m, \u001b[39m1e2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=5'>6</a>\u001b[0m }\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=6'>7</a>\u001b[0m linear_pipe \u001b[39m=\u001b[39m Pipeline(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=7'>8</a>\u001b[0m     steps \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=8'>9</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mfeature_clipper\u001b[39m\u001b[39m'\u001b[39m, Windsorizer()),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=11'>12</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=12'>13</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=13'>14</a>\u001b[0m linear_pipe\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=14'>15</a>\u001b[0m preds \u001b[39m=\u001b[39m linear_pipe\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fpala/2022/sp500/src/notebooks/model_selection.ipynb#ch0000015?line=15'>16</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_true\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mexp(y_test), y_pred\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mexp(preds))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/pipeline.py?line=391'>392</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/pipeline.py?line=392'>393</a>\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/pipeline.py?line=393'>394</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/pipeline.py?line=395'>396</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\integration\\sklearn.py:875\u001b[0m, in \u001b[0;36mOptunaSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=854'>855</a>\u001b[0m objective \u001b[39m=\u001b[39m _Objective(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=855'>856</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=856'>857</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_distributions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=866'>867</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscorer_,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=867'>868</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=869'>870</a>\u001b[0m _logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=870'>871</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSearching the best hyperparameters using \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=871'>872</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msamples...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(_num_samples(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_indices_))\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=872'>873</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=874'>875</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstudy_\u001b[39m.\u001b[39;49moptimize(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=875'>876</a>\u001b[0m     objective, n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, n_trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_trials, timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=876'>877</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=878'>879</a>\u001b[0m _logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mFinished hyperparemeter search!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=880'>881</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=391'>392</a>\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=392'>393</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=393'>394</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=394'>395</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=395'>396</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=396'>397</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=397'>398</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=399'>400</a>\u001b[0m _optimize(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=400'>401</a>\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=401'>402</a>\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=402'>403</a>\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=403'>404</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=404'>405</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=405'>406</a>\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=406'>407</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=407'>408</a>\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=408'>409</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/study.py?line=409'>410</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=63'>64</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=64'>65</a>\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=65'>66</a>\u001b[0m         _optimize_sequential(\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=66'>67</a>\u001b[0m             study,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=67'>68</a>\u001b[0m             func,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=68'>69</a>\u001b[0m             n_trials,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=69'>70</a>\u001b[0m             timeout,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=70'>71</a>\u001b[0m             catch,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=71'>72</a>\u001b[0m             callbacks,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=72'>73</a>\u001b[0m             gc_after_trial,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=73'>74</a>\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=74'>75</a>\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=75'>76</a>\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=76'>77</a>\u001b[0m         )\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=77'>78</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=78'>79</a>\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=159'>160</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=161'>162</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=162'>163</a>\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=163'>164</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=164'>165</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=209'>210</a>\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=211'>212</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=212'>213</a>\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=213'>214</a>\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=214'>215</a>\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/study/_optimize.py?line=215'>216</a>\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\integration\\sklearn.py:229\u001b[0m, in \u001b[0;36m_Objective.__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=226'>227</a>\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross_validate_with_pruning(trial, estimator)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=227'>228</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=228'>229</a>\u001b[0m     scores \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=229'>230</a>\u001b[0m         estimator,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=230'>231</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=231'>232</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=232'>233</a>\u001b[0m         cv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=233'>234</a>\u001b[0m         error_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=234'>235</a>\u001b[0m         fit_params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_params,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=235'>236</a>\u001b[0m         groups\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=236'>237</a>\u001b[0m         return_train_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_train_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=237'>238</a>\u001b[0m         scoring\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=238'>239</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=240'>241</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_scores(trial, scores)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/optuna/integration/sklearn.py?line=242'>243</a>\u001b[0m \u001b[39mreturn\u001b[39;00m trial\u001b[39m.\u001b[39muser_attrs[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=263'>264</a>\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=264'>265</a>\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=265'>266</a>\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=266'>267</a>\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=267'>268</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=268'>269</a>\u001b[0m         clone(estimator),\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=269'>270</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=270'>271</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=271'>272</a>\u001b[0m         scorers,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=272'>273</a>\u001b[0m         train,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=273'>274</a>\u001b[0m         test,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=274'>275</a>\u001b[0m         verbose,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=275'>276</a>\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=276'>277</a>\u001b[0m         fit_params,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=277'>278</a>\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=278'>279</a>\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=279'>280</a>\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=280'>281</a>\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=281'>282</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=282'>283</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=283'>284</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=285'>286</a>\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=287'>288</a>\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=288'>289</a>\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=289'>290</a>\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=677'>678</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=678'>679</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=679'>680</a>\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=681'>682</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=682'>683</a>\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/model_selection/_validation.py?line=683'>684</a>\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_classes.py:484\u001b[0m, in \u001b[0;36mLinearSVR.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=474'>475</a>\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=475'>476</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=476'>477</a>\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=480'>481</a>\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=481'>482</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=482'>483</a>\u001b[0m penalty \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# SVR only accepts l2 penalty\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=483'>484</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _fit_liblinear(\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=484'>485</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=485'>486</a>\u001b[0m     y,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=486'>487</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=487'>488</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=488'>489</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintercept_scaling,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=489'>490</a>\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=490'>491</a>\u001b[0m     penalty,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=491'>492</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=492'>493</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=493'>494</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=494'>495</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=495'>496</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=496'>497</a>\u001b[0m     loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=497'>498</a>\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=498'>499</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=499'>500</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=500'>501</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mravel()\n\u001b[0;32m    <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_classes.py?line=502'>503</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1186\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1182'>1183</a>\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1184'>1185</a>\u001b[0m solver_type \u001b[39m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[1;32m-> <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1185'>1186</a>\u001b[0m raw_coef_, n_iter_ \u001b[39m=\u001b[39m liblinear\u001b[39m.\u001b[39;49mtrain_wrap(\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1186'>1187</a>\u001b[0m     X,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1187'>1188</a>\u001b[0m     y_ind,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1188'>1189</a>\u001b[0m     sp\u001b[39m.\u001b[39;49misspmatrix(X),\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1189'>1190</a>\u001b[0m     solver_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1190'>1191</a>\u001b[0m     tol,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1191'>1192</a>\u001b[0m     bias,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1192'>1193</a>\u001b[0m     C,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1193'>1194</a>\u001b[0m     class_weight_,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1194'>1195</a>\u001b[0m     max_iter,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1195'>1196</a>\u001b[0m     rnd\u001b[39m.\u001b[39;49mrandint(np\u001b[39m.\u001b[39;49miinfo(\u001b[39m\"\u001b[39;49m\u001b[39mi\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mmax),\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1196'>1197</a>\u001b[0m     epsilon,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1197'>1198</a>\u001b[0m     sample_weight,\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1198'>1199</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1199'>1200</a>\u001b[0m \u001b[39m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1200'>1201</a>\u001b[0m \u001b[39m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1201'>1202</a>\u001b[0m \u001b[39m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1202'>1203</a>\u001b[0m \u001b[39m# srand supports\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fpala/AppData/Local/Programs/Python/Python38/lib/site-packages/sklearn/svm/_base.py?line=1203'>1204</a>\u001b[0m n_iter_ \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n_iter_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LinearSVR(max_iter=2000)\n",
    "mse_scorer = make_scorer(custom_score, greater_is_better=False)\n",
    "model_params = {\n",
    "    'C' : optuna.distributions.LogUniformDistribution(1e-2, 1e2)\n",
    "\n",
    "}\n",
    "linear_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('feature_clipper', Windsorizer()),\n",
    "        ('normalizer', PowerTransformer()),\n",
    "        ('optuna', optuna.integration.OptunaSearchCV(model, param_distributions=model_params, scoring=mse_scorer, timeout=300, verbose=1, n_trials=None)),\n",
    "    ]\n",
    ")\n",
    "linear_pipe.fit(X_train,y_train)\n",
    "preds = linear_pipe.predict(X_test)\n",
    "mse = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds))\n",
    "mse , np.sqrt(mse), linear_pipe['optuna'].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM\n",
    "- Better results. Takes way longer to train: time complexity of at least $O(features * observations^3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpala\\AppData\\Local\\Temp\\ipykernel_7264\\414418188.py:12: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  ('optuna', optuna.integration.OptunaSearchCV(model, param_distributions=model_params, scoring=mse_scorer, timeout = 5*60, verbose=1, n_trials=None)),\n",
      "\u001b[32m[I 2022-04-16 17:48:24,824]\u001b[0m A new study created in memory with name: no-name-d3ef95da-a532-439a-b413-a75a5c42db40\u001b[0m\n",
      "\u001b[32m[I 2022-04-16 17:48:24,825]\u001b[0m Searching the best hyperparameters using 6023 samples...\u001b[0m\n",
      "\u001b[32m[I 2022-04-16 17:50:21,130]\u001b[0m Trial 0 finished with value: -4268.632979636355 and parameters: {'C': 19.67816809486007, 'coef0': 0.00012123065428636162}. Best is trial 0 with value: -4268.632979636355.\u001b[0m\n",
      "\u001b[32m[I 2022-04-16 17:50:39,180]\u001b[0m Trial 1 finished with value: -1922.4755296285955 and parameters: {'C': 0.02949793837790296, 'coef0': 83.59202981948808}. Best is trial 1 with value: -1922.4755296285955.\u001b[0m\n",
      "\u001b[32m[I 2022-04-16 17:50:53,676]\u001b[0m Trial 2 finished with value: -3540.6310107337245 and parameters: {'C': 1.2057207247532125, 'coef0': 0.0001732743559625537}. Best is trial 1 with value: -1922.4755296285955.\u001b[0m\n",
      "\u001b[32m[I 2022-04-16 17:51:04,427]\u001b[0m Trial 3 finished with value: -1903.928135338896 and parameters: {'C': 0.035946430923005326, 'coef0': 9.728212644784294}. Best is trial 3 with value: -1903.928135338896.\u001b[0m\n",
      "\u001b[32m[I 2022-04-16 17:51:14,585]\u001b[0m Trial 4 finished with value: -6522.317804679142 and parameters: {'C': 0.0017181792417939297, 'coef0': 0.06828463112404312}. Best is trial 3 with value: -1903.928135338896.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = SVR(kernel = 'poly', degree = 2)\n",
    "mse_scorer = make_scorer(custom_score, greater_is_better=False)\n",
    "model_params = {\n",
    "    'C' : optuna.distributions.LogUniformDistribution(1e-4, 1e2),\n",
    "    'coef0' : optuna.distributions.LogUniformDistribution(1e-4, 1e2),\n",
    "}\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('feature_generator', FeatureGenerator()),\n",
    "        ('feature_clipper', Windsorizer()),\n",
    "        ('normalizer', PowerTransformer()),\n",
    "        ('optuna', optuna.integration.OptunaSearchCV(model, param_distributions=model_params, scoring=mse_scorer, timeout = 5*60, verbose=1, n_trials=None)),\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train,y_train)\n",
    "preds = pipe.predict(X_test)\n",
    "mse = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds))\n",
    "mse , np.sqrt(mse), pipe['optuna'].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n",
    "- Best results yet. Very non-lineal, consider KNN, makes sense because its choosing similar results (maybe previous year results, who knows)\n",
    "- Consider Kmeans or stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 644.7594163029592 25.392113269733166\n",
      "3 593.6485733470453 24.36490454212873\n",
      "4 666.3236454376143 25.813245542504227\n",
      "5 763.7094510753102 27.635293576788907\n",
      "6 782.4422684973629 27.97216953504613\n",
      "7 872.0457021605525 29.530419945550257\n",
      "8 914.3157466215381 30.237654449734325\n",
      "9 973.5795274289509 31.202235936370823\n",
      "10 1029.0056155593766 32.078117394251436\n",
      "11 1075.4788282871746 32.794493871489685\n",
      "12 1138.162558547258 33.736664899590444\n",
      "13 1232.4235865015296 35.10589105123996\n",
      "14 1262.2097767334312 35.5275917665894\n"
     ]
    }
   ],
   "source": [
    "for a in range(2,15):\n",
    "    pipe = Pipeline(\n",
    "        steps = [\n",
    "            ('feature_clipper', Windsorizer()),\n",
    "            ('normalizer', PowerTransformer()),\n",
    "            ('knn', KNeighborsRegressor(n_neighbors=a))\n",
    "        ]\n",
    "    )\n",
    "    pipe.fit(X_train,y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    mse = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds))\n",
    "    print(a, mse , np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans\n",
    "- Inconclusive Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "clusters = []\n",
    "inertias = []\n",
    "ch_scores = []\n",
    "sil_scores = []\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('feature_clipper', Windsorizer()),\n",
    "        ('normalizer', PowerTransformer())\n",
    "    ]\n",
    ")\n",
    "data = pipe.fit_transform(X_train)\n",
    "for a in range(2,20):\n",
    "    print(a)\n",
    "    kmeans = KMeans(n_clusters=a)\n",
    "    kmeans.fit(data)\n",
    "    clusters.append(a)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    ch_scores.append(calinski_harabasz_score(data, kmeans.labels_))\n",
    "    sil_scores.append(silhouette_score(data, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(clusters, inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertias\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(clusters, sil_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(clusters, ch_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"CH score\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> This does not do what I want, I want to transform each observation to de distance to its centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpala\\AppData\\Local\\Temp\\ipykernel_18152\\2181646705.py:13: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  ('random_search', optuna.integration.OptunaSearchCV(model, param_distributions=params, scoring=mse_scorer, n_trials = 10, verbose=5)),\n",
      "\u001b[32m[I 2022-04-17 23:47:56,945]\u001b[0m A new study created in memory with name: no-name-6a001472-deed-45b8-9b6b-a90fee79918e\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:47:56,946]\u001b[0m Searching the best hyperparameters using 5925 samples...\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:48:14,384]\u001b[0m Trial 0 finished with value: -1382.0388206659527 and parameters: {'max_depth': 6, 'min_samples_split': 287, 'n_estimators': 35}. Best is trial 0 with value: -1382.0388206659527.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:48:39,254]\u001b[0m Trial 1 finished with value: -1395.0640694656022 and parameters: {'max_depth': 4, 'min_samples_split': 298, 'n_estimators': 60}. Best is trial 0 with value: -1382.0388206659527.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:49:08,369]\u001b[0m Trial 2 finished with value: -1048.7593943782401 and parameters: {'max_depth': 6, 'min_samples_split': 138, 'n_estimators': 51}. Best is trial 2 with value: -1048.7593943782401.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:49:19,404]\u001b[0m Trial 3 finished with value: -830.0276975444929 and parameters: {'max_depth': 4, 'min_samples_split': 91, 'n_estimators': 25}. Best is trial 3 with value: -830.0276975444929.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:49:30,776]\u001b[0m Trial 4 finished with value: -1349.2493626668472 and parameters: {'max_depth': 3, 'min_samples_split': 101, 'n_estimators': 32}. Best is trial 3 with value: -830.0276975444929.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:49:50,518]\u001b[0m Trial 5 finished with value: -751.0205986523097 and parameters: {'max_depth': 7, 'min_samples_split': 47, 'n_estimators': 28}. Best is trial 5 with value: -751.0205986523097.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:50:35,171]\u001b[0m Trial 6 finished with value: -827.1506922790966 and parameters: {'max_depth': 9, 'min_samples_split': 112, 'n_estimators': 60}. Best is trial 5 with value: -751.0205986523097.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:51:05,768]\u001b[0m Trial 7 finished with value: -804.5731837691014 and parameters: {'max_depth': 6, 'min_samples_split': 71, 'n_estimators': 50}. Best is trial 5 with value: -751.0205986523097.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:51:33,066]\u001b[0m Trial 8 finished with value: -1358.6380961632096 and parameters: {'max_depth': 6, 'min_samples_split': 281, 'n_estimators': 53}. Best is trial 5 with value: -751.0205986523097.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:51:59,235]\u001b[0m Trial 9 finished with value: -823.7178080886595 and parameters: {'max_depth': 4, 'min_samples_split': 26, 'n_estimators': 60}. Best is trial 5 with value: -751.0205986523097.\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:51:59,236]\u001b[0m Finished hyperparemeter search!\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:51:59,238]\u001b[0m Refitting the estimator using 5925 samples...\u001b[0m\n",
      "\u001b[32m[I 2022-04-17 23:52:04,343]\u001b[0m Finished refitting! (elapsed time: 5.103 sec.)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(487.62211972442856, 22.08216745984027)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "mse_scorer = make_scorer(custom_score, greater_is_better=False)\n",
    "params = {\n",
    "    'max_depth' : optuna.distributions.IntUniformDistribution(3, 10),\n",
    "    'min_samples_split' : optuna.distributions.IntUniformDistribution(20, 300),\n",
    "    'n_estimators' : optuna.distributions.IntUniformDistribution(16, 64),\n",
    "}\n",
    "linear_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('feature_clipper', Windsorizer()),\n",
    "        ('normalizer', PowerTransformer()),\n",
    "        ('random_search', optuna.integration.OptunaSearchCV(model, param_distributions=params, scoring=mse_scorer, n_trials = 10, verbose=5)),\n",
    "    ]\n",
    ")\n",
    "linear_pipe.fit(X_train,y_train)\n",
    "preds = linear_pipe.predict(X_test)\n",
    "mse = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds))\n",
    "mse , np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_samples_split': 47, 'n_estimators': 28}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_pipe['random_search'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-18 00:12:18,184]\u001b[0m A new study created in memory with name: no-name-75c22661-5311-4b51-9b63-17b17d814d3f\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:20,490]\u001b[0m Trial 0 finished with value: 1551.8722231030272 and parameters: {'min_child_weight': 255, 'alpha': 3.612614570799724e-06, 'max_depth': 4, 'colsample_bytree': 0.6110366822651868, 'subsample': 0.9030618679204997, 'eta': 0.02720094833464392}. Best is trial 0 with value: 1551.8722231030272.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:22,704]\u001b[0m Trial 1 finished with value: 1248.7327576491066 and parameters: {'min_child_weight': 238, 'alpha': 0.031812027384019635, 'max_depth': 10, 'colsample_bytree': 0.47717709149788645, 'subsample': 0.5998712717824884, 'eta': 0.040490579032080046}. Best is trial 1 with value: 1248.7327576491066.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:24,966]\u001b[0m Trial 2 finished with value: 4103.4673444738855 and parameters: {'min_child_weight': 313, 'alpha': 2.46642672665775e-06, 'max_depth': 4, 'colsample_bytree': 0.7169970731813743, 'subsample': 0.6657403216026834, 'eta': 0.01151421665093256}. Best is trial 1 with value: 1248.7327576491066.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:27,639]\u001b[0m Trial 3 finished with value: 3968.8055015769037 and parameters: {'min_child_weight': 74, 'alpha': 0.2801011934254178, 'max_depth': 8, 'colsample_bytree': 0.5105530899874229, 'subsample': 0.7581198517320618, 'eta': 0.011842824720765158}. Best is trial 1 with value: 1248.7327576491066.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:29,838]\u001b[0m Trial 4 finished with value: 907.3182793732738 and parameters: {'min_child_weight': 319, 'alpha': 0.00023684775098078105, 'max_depth': 4, 'colsample_bytree': 0.601167443673197, 'subsample': 0.6681602898971861, 'eta': 0.18665741160236485}. Best is trial 4 with value: 907.3182793732738.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:32,342]\u001b[0m Trial 5 finished with value: 1265.5969927361903 and parameters: {'min_child_weight': 458, 'alpha': 0.00014036713296669548, 'max_depth': 5, 'colsample_bytree': 0.8207474409098834, 'subsample': 0.8594696100460179, 'eta': 0.05273178627824347}. Best is trial 4 with value: 907.3182793732738.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:35,307]\u001b[0m Trial 6 finished with value: 1107.1664119389588 and parameters: {'min_child_weight': 128, 'alpha': 0.001385681466048584, 'max_depth': 6, 'colsample_bytree': 0.9075426268741434, 'subsample': 0.7549805768106976, 'eta': 0.0278671055708088}. Best is trial 4 with value: 907.3182793732738.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:37,493]\u001b[0m Trial 7 finished with value: 1273.6574639006308 and parameters: {'min_child_weight': 175, 'alpha': 0.00029316091108608927, 'max_depth': 4, 'colsample_bytree': 0.4930286337054337, 'subsample': 0.6278276880559971, 'eta': 0.03327119900214966}. Best is trial 4 with value: 907.3182793732738.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:40,242]\u001b[0m Trial 8 finished with value: 1059.8445434338812 and parameters: {'min_child_weight': 465, 'alpha': 0.0031630016829178285, 'max_depth': 8, 'colsample_bytree': 0.8171170636059166, 'subsample': 0.9812916028241543, 'eta': 0.0714363805713731}. Best is trial 4 with value: 907.3182793732738.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:43,177]\u001b[0m Trial 9 finished with value: 879.807165226247 and parameters: {'min_child_weight': 56, 'alpha': 0.5166643611746086, 'max_depth': 8, 'colsample_bytree': 0.41577233047395046, 'subsample': 0.9350874119303452, 'eta': 0.038234374676884474}. Best is trial 9 with value: 879.807165226247.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:46,636]\u001b[0m Trial 10 finished with value: 540.807194386143 and parameters: {'min_child_weight': 69, 'alpha': 0.9313517827126888, 'max_depth': 10, 'colsample_bytree': 0.9855722998521214, 'subsample': 0.5116243461851825, 'eta': 0.12449897773942536}. Best is trial 10 with value: 540.807194386143.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:50,108]\u001b[0m Trial 11 finished with value: 475.2331142906019 and parameters: {'min_child_weight': 54, 'alpha': 0.5367237119690701, 'max_depth': 10, 'colsample_bytree': 0.9973352030166431, 'subsample': 0.5022178172697148, 'eta': 0.10124281647036901}. Best is trial 11 with value: 475.2331142906019.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:53,121]\u001b[0m Trial 12 finished with value: 612.2494233159103 and parameters: {'min_child_weight': 148, 'alpha': 0.054542989256173555, 'max_depth': 10, 'colsample_bytree': 0.9918374642685994, 'subsample': 0.5038775265489295, 'eta': 0.13403928114821453}. Best is trial 11 with value: 475.2331142906019.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:56,591]\u001b[0m Trial 13 finished with value: 497.6090104277731 and parameters: {'min_child_weight': 59, 'alpha': 0.8721652823891854, 'max_depth': 9, 'colsample_bytree': 0.9958874486187059, 'subsample': 0.5163323679217008, 'eta': 0.09972821018778238}. Best is trial 11 with value: 475.2331142906019.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:12:59,643]\u001b[0m Trial 14 finished with value: 756.2229919055483 and parameters: {'min_child_weight': 192, 'alpha': 0.02738348922044857, 'max_depth': 9, 'colsample_bytree': 0.8960249286132761, 'subsample': 0.5742496498568576, 'eta': 0.08397739854156286}. Best is trial 11 with value: 475.2331142906019.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:01,975]\u001b[0m Trial 15 finished with value: 1346.985839347417 and parameters: {'min_child_weight': 395, 'alpha': 0.1177300303576678, 'max_depth': 7, 'colsample_bytree': 0.9160522450429524, 'subsample': 0.5544181011409511, 'eta': 0.09183100024598852}. Best is trial 11 with value: 475.2331142906019.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:05,188]\u001b[0m Trial 16 finished with value: 426.4717674799116 and parameters: {'min_child_weight': 134, 'alpha': 0.0077907110032252435, 'max_depth': 9, 'colsample_bytree': 0.7844451547280196, 'subsample': 0.6996684948648069, 'eta': 0.1908912627679841}. Best is trial 16 with value: 426.4717674799116.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:08,451]\u001b[0m Trial 17 finished with value: 446.8446598085858 and parameters: {'min_child_weight': 141, 'alpha': 0.004616400426963139, 'max_depth': 9, 'colsample_bytree': 0.7332849943712767, 'subsample': 0.8067901766024422, 'eta': 0.16284807987429475}. Best is trial 16 with value: 426.4717674799116.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:11,681]\u001b[0m Trial 18 finished with value: 434.9443964113611 and parameters: {'min_child_weight': 122, 'alpha': 0.004643710214652216, 'max_depth': 7, 'colsample_bytree': 0.7191194267819351, 'subsample': 0.8092750960716972, 'eta': 0.16934120286521612}. Best is trial 16 with value: 426.4717674799116.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:14,309]\u001b[0m Trial 19 finished with value: 767.7129643468837 and parameters: {'min_child_weight': 198, 'alpha': 2.118164910606819e-05, 'max_depth': 6, 'colsample_bytree': 0.6444875272695435, 'subsample': 0.6926078816983681, 'eta': 0.059964636008416096}. Best is trial 16 with value: 426.4717674799116.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:17,343]\u001b[0m Trial 20 finished with value: 2344.9058649809645 and parameters: {'min_child_weight': 115, 'alpha': 0.008807213184518495, 'max_depth': 7, 'colsample_bytree': 0.7817536229961686, 'subsample': 0.8078150333193465, 'eta': 0.018473573385613347}. Best is trial 16 with value: 426.4717674799116.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:21,031]\u001b[0m Trial 21 finished with value: 409.9584934576774 and parameters: {'min_child_weight': 119, 'alpha': 0.0064805140817314555, 'max_depth': 9, 'colsample_bytree': 0.7091370622982863, 'subsample': 0.8150108560383886, 'eta': 0.19663614378716632}. Best is trial 21 with value: 409.9584934576774.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:24,251]\u001b[0m Trial 22 finished with value: 390.4363813822557 and parameters: {'min_child_weight': 104, 'alpha': 0.0009389398775855479, 'max_depth': 8, 'colsample_bytree': 0.6635392382476262, 'subsample': 0.8227811467729194, 'eta': 0.1952249746111805}. Best is trial 22 with value: 390.4363813822557.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:27,084]\u001b[0m Trial 23 finished with value: 645.7585269019479 and parameters: {'min_child_weight': 223, 'alpha': 0.000862721087603866, 'max_depth': 9, 'colsample_bytree': 0.6451330189232417, 'subsample': 0.7223175822929637, 'eta': 0.13282381463250462}. Best is trial 22 with value: 390.4363813822557.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:30,654]\u001b[0m Trial 24 finished with value: 377.75119668432546 and parameters: {'min_child_weight': 107, 'alpha': 3.6857294728853413e-05, 'max_depth': 8, 'colsample_bytree': 0.7796348615771176, 'subsample': 0.8576622518318837, 'eta': 0.17899741541888894}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:34,045]\u001b[0m Trial 25 finished with value: 413.99515385955664 and parameters: {'min_child_weight': 100, 'alpha': 4.4967706995541014e-05, 'max_depth': 8, 'colsample_bytree': 0.6681517759239526, 'subsample': 0.857929095119741, 'eta': 0.1434116250103332}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:37,070]\u001b[0m Trial 26 finished with value: 508.62370626052643 and parameters: {'min_child_weight': 170, 'alpha': 9.509672399819185e-06, 'max_depth': 8, 'colsample_bytree': 0.5709789227091103, 'subsample': 0.8890867284020805, 'eta': 0.1954312676461715}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:39,815]\u001b[0m Trial 27 finished with value: 755.0484605335084 and parameters: {'min_child_weight': 302, 'alpha': 1.0505901178751917e-06, 'max_depth': 7, 'colsample_bytree': 0.7611677863564394, 'subsample': 0.835556228603101, 'eta': 0.11446014834951754}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:43,392]\u001b[0m Trial 28 finished with value: 467.77814282506773 and parameters: {'min_child_weight': 93, 'alpha': 6.425937817641067e-05, 'max_depth': 6, 'colsample_bytree': 0.8424606114347072, 'subsample': 0.9503195462058756, 'eta': 0.0791531923976203}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:45,808]\u001b[0m Trial 29 finished with value: 708.762768275906 and parameters: {'min_child_weight': 276, 'alpha': 0.0007509070024537172, 'max_depth': 3, 'colsample_bytree': 0.6861976382969763, 'subsample': 0.9063811313068498, 'eta': 0.15416415122533297}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:48,217]\u001b[0m Trial 30 finished with value: 2880.8859533612763 and parameters: {'min_child_weight': 376, 'alpha': 1.57835067930288e-05, 'max_depth': 8, 'colsample_bytree': 0.5727892527343716, 'subsample': 0.7801723087481841, 'eta': 0.018943799045406273}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:51,712]\u001b[0m Trial 31 finished with value: 397.41285313722926 and parameters: {'min_child_weight': 98, 'alpha': 5.831630888735656e-05, 'max_depth': 8, 'colsample_bytree': 0.6481011993787316, 'subsample': 0.8560483751521637, 'eta': 0.14821562101926114}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:55,259]\u001b[0m Trial 32 finished with value: 438.152783809238 and parameters: {'min_child_weight': 93, 'alpha': 8.231914290850114e-05, 'max_depth': 9, 'colsample_bytree': 0.6081965407799211, 'subsample': 0.8768055755322987, 'eta': 0.11459112135332815}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:13:58,287]\u001b[0m Trial 33 finished with value: 476.0024696988212 and parameters: {'min_child_weight': 156, 'alpha': 6.128947651549935e-06, 'max_depth': 7, 'colsample_bytree': 0.7436677266621109, 'subsample': 0.8297254308551922, 'eta': 0.19699826556297279}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:01,330]\u001b[0m Trial 34 finished with value: 566.9979077094725 and parameters: {'min_child_weight': 236, 'alpha': 0.00032070317197788396, 'max_depth': 8, 'colsample_bytree': 0.6650306411193854, 'subsample': 0.9076554901332502, 'eta': 0.15722338010089654}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:04,409]\u001b[0m Trial 35 finished with value: 393.1874563064036 and parameters: {'min_child_weight': 90, 'alpha': 2.8209729307075764e-05, 'max_depth': 9, 'colsample_bytree': 0.5370209548606979, 'subsample': 0.7831366798794743, 'eta': 0.1599748185004455}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:07,268]\u001b[0m Trial 36 finished with value: 468.58474804959616 and parameters: {'min_child_weight': 86, 'alpha': 2.393020455604708e-06, 'max_depth': 8, 'colsample_bytree': 0.5274617353742265, 'subsample': 0.7749311226846228, 'eta': 0.06730466636601921}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:10,067]\u001b[0m Trial 37 finished with value: 682.7266279612819 and parameters: {'min_child_weight': 211, 'alpha': 3.261148951122858e-05, 'max_depth': 10, 'colsample_bytree': 0.4389638850119798, 'subsample': 0.7381175810608275, 'eta': 0.11320847455776602}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:13,011]\u001b[0m Trial 38 finished with value: 643.0549852011013 and parameters: {'min_child_weight': 257, 'alpha': 0.00010990698421569854, 'max_depth': 5, 'colsample_bytree': 0.547749772821709, 'subsample': 0.8572220849229171, 'eta': 0.14329883397812218}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:15,807]\u001b[0m Trial 39 finished with value: 853.6794244105588 and parameters: {'min_child_weight': 166, 'alpha': 0.00018465770460171345, 'max_depth': 8, 'colsample_bytree': 0.4628716169422441, 'subsample': 0.7798792819918808, 'eta': 0.0489111461064191}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:19,586]\u001b[0m Trial 40 finished with value: 398.0565152865152 and parameters: {'min_child_weight': 80, 'alpha': 0.00040210739586159455, 'max_depth': 7, 'colsample_bytree': 0.6277614862166129, 'subsample': 0.9427970170600428, 'eta': 0.16806003292176078}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:22,894]\u001b[0m Trial 41 finished with value: 391.3627069286599 and parameters: {'min_child_weight': 77, 'alpha': 0.0004134157252761531, 'max_depth': 7, 'colsample_bytree': 0.6270021668465334, 'subsample': 0.9879481090185256, 'eta': 0.1675824779362662}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:26,547]\u001b[0m Trial 42 finished with value: 443.8065170169346 and parameters: {'min_child_weight': 108, 'alpha': 0.0015002177177922062, 'max_depth': 8, 'colsample_bytree': 0.5810224557008987, 'subsample': 0.9997651911431293, 'eta': 0.16762534252942285}. Best is trial 24 with value: 377.75119668432546.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:30,326]\u001b[0m Trial 43 finished with value: 364.5151339561605 and parameters: {'min_child_weight': 50, 'alpha': 0.0005067661308481433, 'max_depth': 6, 'colsample_bytree': 0.6919037264269898, 'subsample': 0.9204220948032039, 'eta': 0.12710327513017167}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:33,423]\u001b[0m Trial 44 finished with value: 403.3401717580694 and parameters: {'min_child_weight': 51, 'alpha': 0.0019456076082194193, 'max_depth': 5, 'colsample_bytree': 0.6894452585172, 'subsample': 0.9682658156556335, 'eta': 0.1255386878193811}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:36,382]\u001b[0m Trial 45 finished with value: 417.29258589613454 and parameters: {'min_child_weight': 73, 'alpha': 0.0005354486082200321, 'max_depth': 6, 'colsample_bytree': 0.5212525561600099, 'subsample': 0.9145478186707863, 'eta': 0.09842020077639763}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:39,472]\u001b[0m Trial 46 finished with value: 401.85719743879645 and parameters: {'min_child_weight': 71, 'alpha': 0.00016903660378111062, 'max_depth': 6, 'colsample_bytree': 0.6173229117046867, 'subsample': 0.9764631115449042, 'eta': 0.17338160543660924}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:42,454]\u001b[0m Trial 47 finished with value: 454.93912852936046 and parameters: {'min_child_weight': 143, 'alpha': 0.002362869043728498, 'max_depth': 5, 'colsample_bytree': 0.8139010069433679, 'subsample': 0.9274753689939345, 'eta': 0.1235711868517121}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:45,200]\u001b[0m Trial 48 finished with value: 578.2256962260807 and parameters: {'min_child_weight': 183, 'alpha': 2.3857018407778664e-05, 'max_depth': 7, 'colsample_bytree': 0.492342651166632, 'subsample': 0.879208298863238, 'eta': 0.11011111759728492}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:48,672]\u001b[0m Trial 49 finished with value: 425.3766272411951 and parameters: {'min_child_weight': 71, 'alpha': 1.2050863414752182e-05, 'max_depth': 6, 'colsample_bytree': 0.8546323262173132, 'subsample': 0.9607663569352972, 'eta': 0.08844135870921668}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:51,393]\u001b[0m Trial 50 finished with value: 1105.9004469779507 and parameters: {'min_child_weight': 358, 'alpha': 0.000556682646898845, 'max_depth': 7, 'colsample_bytree': 0.5971455412837223, 'subsample': 0.9983759573223606, 'eta': 0.04010342540159071}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:54,683]\u001b[0m Trial 51 finished with value: 410.0820248361069 and parameters: {'min_child_weight': 106, 'alpha': 5.2220084354439136e-05, 'max_depth': 8, 'colsample_bytree': 0.6643880053132184, 'subsample': 0.8472118481981046, 'eta': 0.14439491318213044}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:14:57,248]\u001b[0m Trial 52 finished with value: 984.601448979067 and parameters: {'min_child_weight': 485, 'alpha': 0.0002493379273507014, 'max_depth': 9, 'colsample_bytree': 0.7501443370064836, 'subsample': 0.8774076607232966, 'eta': 0.17483053287038314}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:00,644]\u001b[0m Trial 53 finished with value: 415.9546529694927 and parameters: {'min_child_weight': 50, 'alpha': 0.0001312688908296156, 'max_depth': 8, 'colsample_bytree': 0.5486001574206529, 'subsample': 0.9205488176961735, 'eta': 0.14697067399428135}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:03,951]\u001b[0m Trial 54 finished with value: 433.15303264654426 and parameters: {'min_child_weight': 128, 'alpha': 6.133974850912788e-06, 'max_depth': 9, 'colsample_bytree': 0.640199939687657, 'subsample': 0.8371846849374874, 'eta': 0.13341320460857878}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:07,356]\u001b[0m Trial 55 finished with value: 392.13412429783517 and parameters: {'min_child_weight': 88, 'alpha': 0.0012139889541111647, 'max_depth': 7, 'colsample_bytree': 0.7120953832075063, 'subsample': 0.8919507964317879, 'eta': 0.17611826967053293}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:10,950]\u001b[0m Trial 56 finished with value: 439.8706841291572 and parameters: {'min_child_weight': 81, 'alpha': 0.0008759526609993341, 'max_depth': 7, 'colsample_bytree': 0.7167438548471534, 'subsample': 0.88857091969162, 'eta': 0.18078050238284327}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:14,177]\u001b[0m Trial 57 finished with value: 956.7556103995869 and parameters: {'min_child_weight': 129, 'alpha': 0.025212620715344906, 'max_depth': 6, 'colsample_bytree': 0.7858591134760959, 'subsample': 0.9378744101119592, 'eta': 0.030781877762282927}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:16,946]\u001b[0m Trial 58 finished with value: 907.3766311551137 and parameters: {'min_child_weight': 418, 'alpha': 0.0013193609571998627, 'max_depth': 7, 'colsample_bytree': 0.6947356400054183, 'subsample': 0.7997042373159302, 'eta': 0.1812552884986261}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:19,648]\u001b[0m Trial 59 finished with value: 580.5376082541234 and parameters: {'min_child_weight': 154, 'alpha': 0.004066359506913976, 'max_depth': 6, 'colsample_bytree': 0.7676853433614855, 'subsample': 0.6330067937128225, 'eta': 0.126928891522735}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:22,948]\u001b[0m Trial 60 finished with value: 4163.455502651457 and parameters: {'min_child_weight': 63, 'alpha': 0.011421600130028747, 'max_depth': 10, 'colsample_bytree': 0.7292633311526201, 'subsample': 0.8988455274097799, 'eta': 0.010207172613842555}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:26,070]\u001b[0m Trial 61 finished with value: 425.67648034566884 and parameters: {'min_child_weight': 106, 'alpha': 3.598792946885606e-05, 'max_depth': 7, 'colsample_bytree': 0.6749719494212416, 'subsample': 0.8561375485696692, 'eta': 0.15560378115993878}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:29,394]\u001b[0m Trial 62 finished with value: 438.56914828699587 and parameters: {'min_child_weight': 90, 'alpha': 7.36492949551972e-05, 'max_depth': 9, 'colsample_bytree': 0.6487562797017846, 'subsample': 0.7957374062779168, 'eta': 0.1986937496702501}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:32,683]\u001b[0m Trial 63 finished with value: 419.37609321224784 and parameters: {'min_child_weight': 116, 'alpha': 0.0005852381716118276, 'max_depth': 8, 'colsample_bytree': 0.7040947358755363, 'subsample': 0.8288333891151896, 'eta': 0.14065857331994566}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:35,554]\u001b[0m Trial 64 finished with value: 441.3302433951501 and parameters: {'min_child_weight': 97, 'alpha': 0.0003173821823398895, 'max_depth': 7, 'colsample_bytree': 0.5960695969839812, 'subsample': 0.7584233942775807, 'eta': 0.16240201099952786}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:38,531]\u001b[0m Trial 65 finished with value: 1776.478904894344 and parameters: {'min_child_weight': 140, 'alpha': 9.932904260995202e-05, 'max_depth': 8, 'colsample_bytree': 0.8013968905723465, 'subsample': 0.8218141939066375, 'eta': 0.022032788923061094}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:41,955]\u001b[0m Trial 66 finished with value: 394.1321227796896 and parameters: {'min_child_weight': 64, 'alpha': 0.0027928491835526323, 'max_depth': 9, 'colsample_bytree': 0.6197168037960107, 'subsample': 0.8724529310058478, 'eta': 0.09917652611121087}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:45,345]\u001b[0m Trial 67 finished with value: 371.27552903175575 and parameters: {'min_child_weight': 59, 'alpha': 0.0027674880300629957, 'max_depth': 9, 'colsample_bytree': 0.5485149046915815, 'subsample': 0.8657813048709606, 'eta': 0.10552439911085247}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:48,672]\u001b[0m Trial 68 finished with value: 418.9864933460141 and parameters: {'min_child_weight': 81, 'alpha': 0.012574318883413305, 'max_depth': 9, 'colsample_bytree': 0.5506416178063793, 'subsample': 0.9539082538212319, 'eta': 0.079101020246942}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:52,036]\u001b[0m Trial 69 finished with value: 414.9469974400295 and parameters: {'min_child_weight': 64, 'alpha': 0.0011785471446792606, 'max_depth': 10, 'colsample_bytree': 0.5009645580687423, 'subsample': 0.8900919833821543, 'eta': 0.10867857392858025}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:54,509]\u001b[0m Trial 70 finished with value: 466.8568011275918 and parameters: {'min_child_weight': 118, 'alpha': 0.0018414406864152193, 'max_depth': 5, 'colsample_bytree': 0.46960492094121825, 'subsample': 0.8409896649463179, 'eta': 0.17898128374787664}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:15:57,973]\u001b[0m Trial 71 finished with value: 382.3534729432421 and parameters: {'min_child_weight': 61, 'alpha': 0.0030578900940442014, 'max_depth': 9, 'colsample_bytree': 0.616561710989332, 'subsample': 0.8691799927625199, 'eta': 0.10046715929765383}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:01,496]\u001b[0m Trial 72 finished with value: 381.57760038494814 and parameters: {'min_child_weight': 53, 'alpha': 0.005433458318630785, 'max_depth': 9, 'colsample_bytree': 0.5857936361694674, 'subsample': 0.8640402348787164, 'eta': 0.11714337997348656}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:04,872]\u001b[0m Trial 73 finished with value: 464.883244430832 and parameters: {'min_child_weight': 54, 'alpha': 0.005576455933367059, 'max_depth': 9, 'colsample_bytree': 0.5859745047807248, 'subsample': 0.8707612561892653, 'eta': 0.07102465510592341}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:08,432]\u001b[0m Trial 74 finished with value: 424.45986806226716 and parameters: {'min_child_weight': 68, 'alpha': 0.0033270742423432806, 'max_depth': 10, 'colsample_bytree': 0.5650125204542046, 'subsample': 0.8990473150713656, 'eta': 0.12023723207551834}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:11,822]\u001b[0m Trial 75 finished with value: 461.67152356509223 and parameters: {'min_child_weight': 79, 'alpha': 0.018510386384391782, 'max_depth': 9, 'colsample_bytree': 0.6258917559842415, 'subsample': 0.928149413069986, 'eta': 0.0600025778318131}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:15,638]\u001b[0m Trial 76 finished with value: 366.5409724253299 and parameters: {'min_child_weight': 57, 'alpha': 0.0010385990449082532, 'max_depth': 10, 'colsample_bytree': 0.6718645400028476, 'subsample': 0.9143283864689697, 'eta': 0.13492944041269594}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:19,543]\u001b[0m Trial 77 finished with value: 423.5162489482378 and parameters: {'min_child_weight': 53, 'alpha': 0.099337521507568, 'max_depth': 10, 'colsample_bytree': 0.6775255510480755, 'subsample': 0.9092785974421952, 'eta': 0.09231373287479346}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:22,964]\u001b[0m Trial 78 finished with value: 459.73392660278483 and parameters: {'min_child_weight': 104, 'alpha': 0.006994059909124265, 'max_depth': 10, 'colsample_bytree': 0.6371971075371621, 'subsample': 0.8650106287338223, 'eta': 0.10141998097507786}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:26,895]\u001b[0m Trial 79 finished with value: 381.3419213526433 and parameters: {'min_child_weight': 60, 'alpha': 0.0004442339249270885, 'max_depth': 10, 'colsample_bytree': 0.654393921911597, 'subsample': 0.9812942873334298, 'eta': 0.1329769249516561}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:30,753]\u001b[0m Trial 80 finished with value: 403.1295946934977 and parameters: {'min_child_weight': 63, 'alpha': 0.0009130633079995572, 'max_depth': 10, 'colsample_bytree': 0.6565919035587436, 'subsample': 0.9440574450770918, 'eta': 0.13236532024957498}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:34,419]\u001b[0m Trial 81 finished with value: 417.6784101214785 and parameters: {'min_child_weight': 78, 'alpha': 0.002107781975002706, 'max_depth': 10, 'colsample_bytree': 0.5999193065925243, 'subsample': 0.986381095349256, 'eta': 0.10359674343976578}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:38,437]\u001b[0m Trial 82 finished with value: 379.4878683919822 and parameters: {'min_child_weight': 50, 'alpha': 0.00048277798706888414, 'max_depth': 10, 'colsample_bytree': 0.6892276121273452, 'subsample': 0.9710250188288662, 'eta': 0.12184309759762708}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:43,077]\u001b[0m Trial 83 finished with value: 404.2242786480302 and parameters: {'min_child_weight': 61, 'alpha': 0.0006220055553728155, 'max_depth': 10, 'colsample_bytree': 0.9690712385214699, 'subsample': 0.9605235679639335, 'eta': 0.12146062646347748}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:47,056]\u001b[0m Trial 84 finished with value: 369.56212448006335 and parameters: {'min_child_weight': 50, 'alpha': 0.0030820589424933502, 'max_depth': 10, 'colsample_bytree': 0.6824705075860875, 'subsample': 0.971835183847365, 'eta': 0.08154377127862747}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:51,186]\u001b[0m Trial 85 finished with value: 390.5962582954184 and parameters: {'min_child_weight': 50, 'alpha': 0.004042678309840312, 'max_depth': 10, 'colsample_bytree': 0.7274136377583237, 'subsample': 0.9762602203710535, 'eta': 0.09112415834212938}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:54,985]\u001b[0m Trial 86 finished with value: 396.2682470107722 and parameters: {'min_child_weight': 70, 'alpha': 0.01008750095130566, 'max_depth': 10, 'colsample_bytree': 0.692251267416714, 'subsample': 0.9297497829356824, 'eta': 0.08469512189272162}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:16:58,984]\u001b[0m Trial 87 finished with value: 370.6980062155239 and parameters: {'min_child_weight': 50, 'alpha': 0.002882521159580879, 'max_depth': 10, 'colsample_bytree': 0.6835204861080136, 'subsample': 0.9660812292333021, 'eta': 0.10742134928611514}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:02,908]\u001b[0m Trial 88 finished with value: 415.43300943700626 and parameters: {'min_child_weight': 91, 'alpha': 0.0529510777973624, 'max_depth': 10, 'colsample_bytree': 0.7447160739600583, 'subsample': 0.9682219276660557, 'eta': 0.11219263579608386}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:06,874]\u001b[0m Trial 89 finished with value: 369.7373048880997 and parameters: {'min_child_weight': 50, 'alpha': 0.0017208169897211891, 'max_depth': 10, 'colsample_bytree': 0.6747220998435677, 'subsample': 0.9505393122744078, 'eta': 0.07678921370384346}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:10,649]\u001b[0m Trial 90 finished with value: 407.52212776201463 and parameters: {'min_child_weight': 73, 'alpha': 0.00044154699631578304, 'max_depth': 10, 'colsample_bytree': 0.6819973619582345, 'subsample': 0.9510668290277323, 'eta': 0.06400005377511876}. Best is trial 43 with value: 364.5151339561605.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:14,680]\u001b[0m Trial 91 finished with value: 337.0709845015816 and parameters: {'min_child_weight': 58, 'alpha': 0.005431704895799771, 'max_depth': 10, 'colsample_bytree': 0.7063898876659078, 'subsample': 0.9724863280502848, 'eta': 0.08220319061595308}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:17,974]\u001b[0m Trial 92 finished with value: 506.4947057800332 and parameters: {'min_child_weight': 50, 'alpha': 0.0015523783606349892, 'max_depth': 10, 'colsample_bytree': 0.403835166221697, 'subsample': 0.9681535751797643, 'eta': 0.0779169403231647}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:21,767]\u001b[0m Trial 93 finished with value: 435.25414478726873 and parameters: {'min_child_weight': 85, 'alpha': 0.00020342608826738829, 'max_depth': 10, 'colsample_bytree': 0.7008237665049402, 'subsample': 0.980935161761347, 'eta': 0.07613725185228841}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:25,937]\u001b[0m Trial 94 finished with value: 437.0380929216005 and parameters: {'min_child_weight': 63, 'alpha': 0.0020651818016745754, 'max_depth': 10, 'colsample_bytree': 0.7194511742734963, 'subsample': 0.9888224164685738, 'eta': 0.05533434397604446}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:29,957]\u001b[0m Trial 95 finished with value: 390.3754701094676 and parameters: {'min_child_weight': 72, 'alpha': 0.01588322409071266, 'max_depth': 10, 'colsample_bytree': 0.7659839678973674, 'subsample': 0.9403502353662827, 'eta': 0.09402338078664983}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:33,298]\u001b[0m Trial 96 finished with value: 553.5497734102493 and parameters: {'min_child_weight': 98, 'alpha': 0.0006917594525005649, 'max_depth': 10, 'colsample_bytree': 0.6547554167638806, 'subsample': 0.9215620823254301, 'eta': 0.04677042133177315}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:37,549]\u001b[0m Trial 97 finished with value: 435.07589628195734 and parameters: {'min_child_weight': 59, 'alpha': 0.00271309744705119, 'max_depth': 10, 'colsample_bytree': 0.8354203213472937, 'subsample': 0.9592595991786285, 'eta': 0.08358368748716398}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:41,252]\u001b[0m Trial 98 finished with value: 437.3477223609743 and parameters: {'min_child_weight': 84, 'alpha': 0.0010862304982601184, 'max_depth': 10, 'colsample_bytree': 0.6695049652428235, 'subsample': 0.9705742907875593, 'eta': 0.07351273264454616}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:44,332]\u001b[0m Trial 99 finished with value: 711.3963585212072 and parameters: {'min_child_weight': 316, 'alpha': 0.008008777050185252, 'max_depth': 10, 'colsample_bytree': 0.733771721103046, 'subsample': 0.9986768001081563, 'eta': 0.10605595327111726}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:47,396]\u001b[0m Trial 100 finished with value: 669.7790928699844 and parameters: {'min_child_weight': 291, 'alpha': 0.00036496413396112064, 'max_depth': 10, 'colsample_bytree': 0.7027500191469699, 'subsample': 0.9473670850402292, 'eta': 0.1319005719491892}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:51,084]\u001b[0m Trial 101 finished with value: 366.246896106382 and parameters: {'min_child_weight': 51, 'alpha': 0.005471783927312535, 'max_depth': 9, 'colsample_bytree': 0.6855972131109449, 'subsample': 0.9159067416288535, 'eta': 0.11819456465315574}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:54,819]\u001b[0m Trial 102 finished with value: 432.54497941359534 and parameters: {'min_child_weight': 50, 'alpha': 0.003435784797175525, 'max_depth': 9, 'colsample_bytree': 0.6912672316036753, 'subsample': 0.9127274126559253, 'eta': 0.08587604891341535}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:17:58,737]\u001b[0m Trial 103 finished with value: 431.86006859686404 and parameters: {'min_child_weight': 72, 'alpha': 0.0015618918543730887, 'max_depth': 10, 'colsample_bytree': 0.683806532364023, 'subsample': 0.9363617398848345, 'eta': 0.13877073863633432}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:02,890]\u001b[0m Trial 104 finished with value: 406.3796095410527 and parameters: {'min_child_weight': 60, 'alpha': 0.005025089582828366, 'max_depth': 9, 'colsample_bytree': 0.8666056831147853, 'subsample': 0.9592084832358209, 'eta': 0.15129871945005366}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:06,592]\u001b[0m Trial 105 finished with value: 399.88818397145764 and parameters: {'min_child_weight': 112, 'alpha': 0.0023775184605134537, 'max_depth': 9, 'colsample_bytree': 0.7564961762202523, 'subsample': 0.9775859089284038, 'eta': 0.1263606159896767}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:10,117]\u001b[0m Trial 106 finished with value: 450.68574885415927 and parameters: {'min_child_weight': 96, 'alpha': 0.0007421370431006358, 'max_depth': 10, 'colsample_bytree': 0.6638304600359349, 'subsample': 0.9195738530560469, 'eta': 0.06669215741876015}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:14,059]\u001b[0m Trial 107 finished with value: 385.3542933631126 and parameters: {'min_child_weight': 78, 'alpha': 0.006432599664543232, 'max_depth': 10, 'colsample_bytree': 0.7340708625171708, 'subsample': 0.9891096372347258, 'eta': 0.09558941280560695}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:16,286]\u001b[0m Trial 108 finished with value: 862.6327631161704 and parameters: {'min_child_weight': 342, 'alpha': 0.0002701547009407516, 'max_depth': 3, 'colsample_bytree': 0.6369833881723557, 'subsample': 0.9300258642244139, 'eta': 0.10719597447370519}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:20,242]\u001b[0m Trial 109 finished with value: 344.17370187392265 and parameters: {'min_child_weight': 66, 'alpha': 0.0038448055967223536, 'max_depth': 10, 'colsample_bytree': 0.7107769297977408, 'subsample': 0.9511412415171147, 'eta': 0.12081600834339039}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:24,072]\u001b[0m Trial 110 finished with value: 390.11960876249765 and parameters: {'min_child_weight': 87, 'alpha': 0.004046440324175473, 'max_depth': 9, 'colsample_bytree': 0.7807890595581984, 'subsample': 0.9484454416586628, 'eta': 0.1198156701793097}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:28,094]\u001b[0m Trial 111 finished with value: 349.89184782143104 and parameters: {'min_child_weight': 66, 'alpha': 0.001602809461023549, 'max_depth': 10, 'colsample_bytree': 0.712553492074663, 'subsample': 0.9702380062183426, 'eta': 0.11408006205376021}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:32,050]\u001b[0m Trial 112 finished with value: 374.9931195370921 and parameters: {'min_child_weight': 70, 'alpha': 0.001747339878111916, 'max_depth': 10, 'colsample_bytree': 0.7133672327249038, 'subsample': 0.964249348814777, 'eta': 0.11644005712053283}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:36,056]\u001b[0m Trial 113 finished with value: 413.5378923264195 and parameters: {'min_child_weight': 69, 'alpha': 0.0018134481609248358, 'max_depth': 10, 'colsample_bytree': 0.7151992936117746, 'subsample': 0.9559878260355987, 'eta': 0.11119082207878139}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:39,796]\u001b[0m Trial 114 finished with value: 431.9359191118117 and parameters: {'min_child_weight': 80, 'alpha': 0.0028517963804027147, 'max_depth': 10, 'colsample_bytree': 0.7092245931426713, 'subsample': 0.9026593474271086, 'eta': 0.09648182866646446}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:43,732]\u001b[0m Trial 115 finished with value: 405.9425269433285 and parameters: {'min_child_weight': 69, 'alpha': 0.009345750483829626, 'max_depth': 10, 'colsample_bytree': 0.7481696425971949, 'subsample': 0.9319976592057548, 'eta': 0.08218244747104127}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:47,536]\u001b[0m Trial 116 finished with value: 423.1663150529194 and parameters: {'min_child_weight': 59, 'alpha': 0.0012496473867980216, 'max_depth': 9, 'colsample_bytree': 0.7266892945999088, 'subsample': 0.9168774090453149, 'eta': 0.10605033743497821}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:50,786]\u001b[0m Trial 117 finished with value: 3062.196880257232 and parameters: {'min_child_weight': 88, 'alpha': 0.004358180194869907, 'max_depth': 10, 'colsample_bytree': 0.6724622287665483, 'subsample': 0.9407598588474486, 'eta': 0.015119080953062055}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:54,534]\u001b[0m Trial 118 finished with value: 393.9012253314215 and parameters: {'min_child_weight': 104, 'alpha': 0.015370119927489708, 'max_depth': 9, 'colsample_bytree': 0.7746390583155485, 'subsample': 0.9509524791311147, 'eta': 0.14238285670402015}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:18:58,303]\u001b[0m Trial 119 finished with value: 400.51634616847565 and parameters: {'min_child_weight': 74, 'alpha': 1.85172101051317e-06, 'max_depth': 10, 'colsample_bytree': 0.7046343862320614, 'subsample': 0.884570423988825, 'eta': 0.11444079855383589}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:01,528]\u001b[0m Trial 120 finished with value: 414.6237433361464 and parameters: {'min_child_weight': 61, 'alpha': 0.006857676341602014, 'max_depth': 6, 'colsample_bytree': 0.7363563623388505, 'subsample': 0.9624555203062773, 'eta': 0.09032719628030625}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:05,879]\u001b[0m Trial 121 finished with value: 402.6760400130461 and parameters: {'min_child_weight': 50, 'alpha': 0.0009876721855530176, 'max_depth': 10, 'colsample_bytree': 0.6846422236609745, 'subsample': 0.9699472944599498, 'eta': 0.12690263057570766}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:11,037]\u001b[0m Trial 122 finished with value: 416.3325889438726 and parameters: {'min_child_weight': 50, 'alpha': 0.0022435750490387564, 'max_depth': 10, 'colsample_bytree': 0.7971458765553686, 'subsample': 0.9892743691081388, 'eta': 0.1196329111270113}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:15,404]\u001b[0m Trial 123 finished with value: 375.6336592543223 and parameters: {'min_child_weight': 69, 'alpha': 0.001635377438912218, 'max_depth': 10, 'colsample_bytree': 0.6957442734954874, 'subsample': 0.9731919297566086, 'eta': 0.13611500916319852}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:19,332]\u001b[0m Trial 124 finished with value: 379.70276117225023 and parameters: {'min_child_weight': 95, 'alpha': 0.0016567033537998397, 'max_depth': 10, 'colsample_bytree': 0.7000392417488729, 'subsample': 0.9405588695105527, 'eta': 0.15341498754188193}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:23,308]\u001b[0m Trial 125 finished with value: 376.43517665477106 and parameters: {'min_child_weight': 67, 'alpha': 0.0038233012097269575, 'max_depth': 10, 'colsample_bytree': 0.7223491178008243, 'subsample': 0.9235299208057716, 'eta': 0.13614012928348032}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:27,441]\u001b[0m Trial 126 finished with value: 387.6617602031027 and parameters: {'min_child_weight': 68, 'alpha': 0.0052307140199202426, 'max_depth': 10, 'colsample_bytree': 0.7230997042433627, 'subsample': 0.922051817440842, 'eta': 0.1361533509774615}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:30,641]\u001b[0m Trial 127 finished with value: 467.9674020991728 and parameters: {'min_child_weight': 77, 'alpha': 0.003364789942883998, 'max_depth': 10, 'colsample_bytree': 0.7120665001074973, 'subsample': 0.5379975288687442, 'eta': 0.11402595640080007}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:34,722]\u001b[0m Trial 128 finished with value: 439.5030128677089 and parameters: {'min_child_weight': 59, 'alpha': 0.0026773711114774913, 'max_depth': 10, 'colsample_bytree': 0.6792606151753982, 'subsample': 0.8978947452512539, 'eta': 0.10420149183206508}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:37,157]\u001b[0m Trial 129 finished with value: 916.9374593880107 and parameters: {'min_child_weight': 437, 'alpha': 0.0014167997522258153, 'max_depth': 10, 'colsample_bytree': 0.4362986768368643, 'subsample': 0.9640333313295908, 'eta': 0.14875448679040748}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:41,346]\u001b[0m Trial 130 finished with value: 389.4819973551465 and parameters: {'min_child_weight': 68, 'alpha': 0.0009234409338652493, 'max_depth': 10, 'colsample_bytree': 0.6969358169836534, 'subsample': 0.9944822918182025, 'eta': 0.1268611729244642}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:45,327]\u001b[0m Trial 131 finished with value: 395.4694423901539 and parameters: {'min_child_weight': 80, 'alpha': 0.0035632650950291117, 'max_depth': 10, 'colsample_bytree': 0.7535296158860255, 'subsample': 0.9523773969659648, 'eta': 0.13807032602795016}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:49,193]\u001b[0m Trial 132 finished with value: 402.659144622019 and parameters: {'min_child_weight': 58, 'alpha': 0.0020983098448837186, 'max_depth': 9, 'colsample_bytree': 0.6618002844475579, 'subsample': 0.9807897266803811, 'eta': 0.1604245933592582}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:52,451]\u001b[0m Trial 133 finished with value: 661.6269902183462 and parameters: {'min_child_weight': 252, 'alpha': 0.005029945614602794, 'max_depth': 10, 'colsample_bytree': 0.7418309548423041, 'subsample': 0.9113656837143446, 'eta': 0.098301527077094}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:19:56,724]\u001b[0m Trial 134 finished with value: 416.81353123294843 and parameters: {'min_child_weight': 89, 'alpha': 0.0076449011206932245, 'max_depth': 10, 'colsample_bytree': 0.7120965593429543, 'subsample': 0.9335117356856104, 'eta': 0.11451426614817169}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:00,117]\u001b[0m Trial 135 finished with value: 377.2484414819054 and parameters: {'min_child_weight': 65, 'alpha': 0.002590713379780118, 'max_depth': 6, 'colsample_bytree': 0.6709944024948143, 'subsample': 0.9751498070443381, 'eta': 0.13157157395745292}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:03,142]\u001b[0m Trial 136 finished with value: 665.058492865176 and parameters: {'min_child_weight': 66, 'alpha': 0.0013622052411159918, 'max_depth': 5, 'colsample_bytree': 0.6735058371573226, 'subsample': 0.9736166999324529, 'eta': 0.03575103984278181}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:06,257]\u001b[0m Trial 137 finished with value: 369.9232827626688 and parameters: {'min_child_weight': 57, 'alpha': 0.0025979027702155823, 'max_depth': 6, 'colsample_bytree': 0.6388172660926312, 'subsample': 0.9476281125443264, 'eta': 0.1318888707075967}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:09,484]\u001b[0m Trial 138 finished with value: 425.64353503361497 and parameters: {'min_child_weight': 76, 'alpha': 0.0017006641383266726, 'max_depth': 6, 'colsample_bytree': 0.6457383807138638, 'subsample': 0.7033796849925803, 'eta': 0.1437146271459369}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:12,703]\u001b[0m Trial 139 finished with value: 400.6226302364291 and parameters: {'min_child_weight': 57, 'alpha': 0.003812565912894742, 'max_depth': 6, 'colsample_bytree': 0.6945307037913951, 'subsample': 0.94395414427603, 'eta': 0.1192605605060591}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:15,815]\u001b[0m Trial 140 finished with value: 400.5443800654566 and parameters: {'min_child_weight': 57, 'alpha': 0.0007669302268234547, 'max_depth': 6, 'colsample_bytree': 0.6337804038633545, 'subsample': 0.9571167398211646, 'eta': 0.08878818678757357}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:19,010]\u001b[0m Trial 141 finished with value: 363.5612243007434 and parameters: {'min_child_weight': 67, 'alpha': 0.002468018494374398, 'max_depth': 6, 'colsample_bytree': 0.673004312128294, 'subsample': 0.9800050951987238, 'eta': 0.12977212161773985}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:23,545]\u001b[0m Trial 142 finished with value: 370.3302974836458 and parameters: {'min_child_weight': 50, 'alpha': 0.001073013228998358, 'max_depth': 10, 'colsample_bytree': 0.6818628215186161, 'subsample': 0.9818333679127623, 'eta': 0.12844842069955403}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:27,023]\u001b[0m Trial 143 finished with value: 385.04958938642943 and parameters: {'min_child_weight': 57, 'alpha': 0.0009662669887395888, 'max_depth': 6, 'colsample_bytree': 0.6564275298366194, 'subsample': 0.9816063461486046, 'eta': 0.109030350162615}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:30,521]\u001b[0m Trial 144 finished with value: 356.67886791109567 and parameters: {'min_child_weight': 50, 'alpha': 0.0012495371139676604, 'max_depth': 6, 'colsample_bytree': 0.6825992220258157, 'subsample': 0.9998250941499486, 'eta': 0.12411742385528798}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:33,969]\u001b[0m Trial 145 finished with value: 347.9286414346394 and parameters: {'min_child_weight': 50, 'alpha': 0.0012509591710724282, 'max_depth': 6, 'colsample_bytree': 0.6842599246731399, 'subsample': 0.9959017000990739, 'eta': 0.12767747593973128}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:37,285]\u001b[0m Trial 146 finished with value: 368.67027784998305 and parameters: {'min_child_weight': 51, 'alpha': 0.0012054098838114903, 'max_depth': 6, 'colsample_bytree': 0.6812848643901848, 'subsample': 0.9845579559666617, 'eta': 0.12325393355352149}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:40,579]\u001b[0m Trial 147 finished with value: 381.7995372806567 and parameters: {'min_child_weight': 50, 'alpha': 0.0006177646214894997, 'max_depth': 6, 'colsample_bytree': 0.6475617127248717, 'subsample': 0.9998707008920305, 'eta': 0.1267383888387869}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:44,024]\u001b[0m Trial 148 finished with value: 393.86383066550536 and parameters: {'min_child_weight': 83, 'alpha': 0.0008752279468429996, 'max_depth': 6, 'colsample_bytree': 0.6792839928605214, 'subsample': 0.9902026039488865, 'eta': 0.12701793406711762}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:47,075]\u001b[0m Trial 149 finished with value: 382.8176318310078 and parameters: {'min_child_weight': 52, 'alpha': 0.0013854141552644174, 'max_depth': 5, 'colsample_bytree': 0.6659861505158502, 'subsample': 0.9857680107545932, 'eta': 0.1455211826073146}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:50,776]\u001b[0m Trial 150 finished with value: 414.29660655174416 and parameters: {'min_child_weight': 61, 'alpha': 0.0010969173838258474, 'max_depth': 6, 'colsample_bytree': 0.6832345093889916, 'subsample': 0.9995821021110496, 'eta': 0.1240094115370395}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:54,170]\u001b[0m Trial 151 finished with value: 388.7900631179991 and parameters: {'min_child_weight': 59, 'alpha': 0.002245802105385662, 'max_depth': 6, 'colsample_bytree': 0.6882753282695885, 'subsample': 0.9837358159641661, 'eta': 0.10032327471805329}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:20:57,522]\u001b[0m Trial 152 finished with value: 365.25564787029043 and parameters: {'min_child_weight': 51, 'alpha': 0.0029148192820800975, 'max_depth': 6, 'colsample_bytree': 0.6552637261723079, 'subsample': 0.9619366324764297, 'eta': 0.10778060463749249}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:00,886]\u001b[0m Trial 153 finished with value: 419.92394050441624 and parameters: {'min_child_weight': 78, 'alpha': 0.0011109076102164546, 'max_depth': 6, 'colsample_bytree': 0.6547479280981923, 'subsample': 0.9626822155332968, 'eta': 0.11184114580330451}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:04,182]\u001b[0m Trial 154 finished with value: 391.43506760860157 and parameters: {'min_child_weight': 50, 'alpha': 0.0006876211455899495, 'max_depth': 6, 'colsample_bytree': 0.6100412302020349, 'subsample': 0.9915257994757675, 'eta': 0.12129982066806064}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:07,743]\u001b[0m Trial 155 finished with value: 408.31129064227395 and parameters: {'min_child_weight': 50, 'alpha': 0.0028258126736115954, 'max_depth': 6, 'colsample_bytree': 0.6680770420287464, 'subsample': 0.9756697621934755, 'eta': 0.0699813730470542}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:10,955]\u001b[0m Trial 156 finished with value: 448.8418217567439 and parameters: {'min_child_weight': 65, 'alpha': 0.005793754156683752, 'max_depth': 6, 'colsample_bytree': 0.6431056951501753, 'subsample': 0.952016284390352, 'eta': 0.05336756949898628}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:14,712]\u001b[0m Trial 157 finished with value: 393.1081153204689 and parameters: {'min_child_weight': 75, 'alpha': 0.0019673036100387948, 'max_depth': 6, 'colsample_bytree': 0.626908745642527, 'subsample': 0.9668509122539022, 'eta': 0.13093117977116853}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:17,992]\u001b[0m Trial 158 finished with value: 413.08082136570584 and parameters: {'min_child_weight': 59, 'alpha': 0.0005345039339037359, 'max_depth': 6, 'colsample_bytree': 0.7018641046696047, 'subsample': 0.9814133249198617, 'eta': 0.1538755328604925}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:21,199]\u001b[0m Trial 159 finished with value: 412.99660427276115 and parameters: {'min_child_weight': 85, 'alpha': 0.001220629145025781, 'max_depth': 6, 'colsample_bytree': 0.675910658858326, 'subsample': 0.9459794819586956, 'eta': 0.10486754393356304}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:24,382]\u001b[0m Trial 160 finished with value: 407.30289762532175 and parameters: {'min_child_weight': 72, 'alpha': 0.0030683159923354567, 'max_depth': 6, 'colsample_bytree': 0.6581058782430295, 'subsample': 0.9579167316052127, 'eta': 0.11704591001021744}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:27,558]\u001b[0m Trial 161 finished with value: 369.81586718184946 and parameters: {'min_child_weight': 60, 'alpha': 0.0024040955735217103, 'max_depth': 6, 'colsample_bytree': 0.6910622218327376, 'subsample': 0.9915375331960967, 'eta': 0.10861001791438363}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:31,137]\u001b[0m Trial 162 finished with value: 391.0760246386649 and parameters: {'min_child_weight': 63, 'alpha': 0.002092895078548799, 'max_depth': 6, 'colsample_bytree': 0.6851851356312757, 'subsample': 0.9923374600454422, 'eta': 0.10894698155001005}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:34,278]\u001b[0m Trial 163 finished with value: 378.13553341464996 and parameters: {'min_child_weight': 50, 'alpha': 0.003907419846468551, 'max_depth': 5, 'colsample_bytree': 0.6920516628636545, 'subsample': 0.9726528058256123, 'eta': 0.09330699504685051}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:36,705]\u001b[0m Trial 164 finished with value: 391.05640738597106 and parameters: {'min_child_weight': 58, 'alpha': 0.004826482513643522, 'max_depth': 4, 'colsample_bytree': 0.7087236948142616, 'subsample': 0.6213341803445475, 'eta': 0.1381766588983294}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:39,946]\u001b[0m Trial 165 finished with value: 397.3820462447959 and parameters: {'min_child_weight': 68, 'alpha': 0.002500458239335183, 'max_depth': 6, 'colsample_bytree': 0.6673225472151627, 'subsample': 0.9982956529812522, 'eta': 0.12156767781886585}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:43,115]\u001b[0m Trial 166 finished with value: 381.25312849557133 and parameters: {'min_child_weight': 75, 'alpha': 0.0014934303229377055, 'max_depth': 6, 'colsample_bytree': 0.6804137714195717, 'subsample': 0.9844895269200037, 'eta': 0.10186563264304357}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:46,348]\u001b[0m Trial 167 finished with value: 397.73390191050527 and parameters: {'min_child_weight': 50, 'alpha': 0.009490120837714373, 'max_depth': 6, 'colsample_bytree': 0.6981222710662531, 'subsample': 0.9658539373262595, 'eta': 0.08114837682146434}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:49,199]\u001b[0m Trial 168 finished with value: 413.2431401496242 and parameters: {'min_child_weight': 64, 'alpha': 0.0008652504979251769, 'max_depth': 5, 'colsample_bytree': 0.6517237518415702, 'subsample': 0.9386368560209425, 'eta': 0.13092395823354705}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:52,342]\u001b[0m Trial 169 finished with value: 494.86862372915886 and parameters: {'min_child_weight': 93, 'alpha': 0.0018837602053569608, 'max_depth': 6, 'colsample_bytree': 0.720602537480093, 'subsample': 0.9767906031870712, 'eta': 0.06048630684645187}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:55,376]\u001b[0m Trial 170 finished with value: 432.1399113955798 and parameters: {'min_child_weight': 83, 'alpha': 0.006333399685593334, 'max_depth': 6, 'colsample_bytree': 0.6753567390140551, 'subsample': 0.9527565578745096, 'eta': 0.11395683552471024}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:21:58,790]\u001b[0m Trial 171 finished with value: 370.48558091617076 and parameters: {'min_child_weight': 59, 'alpha': 0.003257051847865241, 'max_depth': 7, 'colsample_bytree': 0.6913680921126703, 'subsample': 0.9875966638426107, 'eta': 0.108129188406632}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:22:02,285]\u001b[0m Trial 172 finished with value: 390.7711109325371 and parameters: {'min_child_weight': 58, 'alpha': 0.003060481123036597, 'max_depth': 7, 'colsample_bytree': 0.6901203962352872, 'subsample': 0.9885228533184489, 'eta': 0.10944766462577636}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:22:05,366]\u001b[0m Trial 173 finished with value: 590.4574443876628 and parameters: {'min_child_weight': 207, 'alpha': 0.004412453483773645, 'max_depth': 6, 'colsample_bytree': 0.7041405962404579, 'subsample': 0.9994972450762599, 'eta': 0.12050801052567807}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:22:08,515]\u001b[0m Trial 174 finished with value: 391.40315958807037 and parameters: {'min_child_weight': 69, 'alpha': 0.0013184533324540506, 'max_depth': 6, 'colsample_bytree': 0.6630501703744605, 'subsample': 0.9668285154787253, 'eta': 0.09631954935019407}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:22:11,668]\u001b[0m Trial 175 finished with value: 365.6986360048082 and parameters: {'min_child_weight': 59, 'alpha': 0.002550865407196219, 'max_depth': 6, 'colsample_bytree': 0.6838138674398389, 'subsample': 0.9840761023026635, 'eta': 0.12936386129948188}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:22:14,749]\u001b[0m Trial 176 finished with value: 360.5810750629159 and parameters: {'min_child_weight': 59, 'alpha': 0.0023048253055868127, 'max_depth': 6, 'colsample_bytree': 0.6390763668350733, 'subsample': 0.9849412503173038, 'eta': 0.1441508390976061}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:22:17,857]\u001b[0m Trial 177 finished with value: 449.0393410928134 and parameters: {'min_child_weight': 76, 'alpha': 0.0021064692967644864, 'max_depth': 6, 'colsample_bytree': 0.6299744193435317, 'subsample': 0.979276042010779, 'eta': 0.16312287457873323}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n",
      "\u001b[32m[I 2022-04-18 00:22:20,950]\u001b[0m Trial 178 finished with value: 363.16032741404007 and parameters: {'min_child_weight': 66, 'alpha': 0.0011457881634473583, 'max_depth': 6, 'colsample_bytree': 0.6432094721421445, 'subsample': 0.9778374759351708, 'eta': 0.14800930404162385}. Best is trial 91 with value: 337.0709845015816.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params={\n",
    "        \"verbosity\": 1,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 50, 500),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 1.0, log=True),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.4, 1),\n",
    "        \"subsample\" : trial.suggest_float(\"subsample\", 0.5, 1),\n",
    "        \"eta\" : trial.suggest_float(\"eta\", 1e-2, 0.2, log=True)\n",
    "        }\n",
    "    xgb_pipe = Pipeline(\n",
    "        steps = [\n",
    "            ('feature_clipper', Windsorizer()),\n",
    "            ('normalizer', PowerTransformer()),\n",
    "            ('xgb', XGBRegressor(**params)),\n",
    "        ]\n",
    "    )\n",
    "    xgb_pipe.fit(X_train,y_train)\n",
    "    preds = xgb_pipe.predict(X_test)\n",
    "    mse = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds))\n",
    "    return mse\n",
    "\n",
    "minutes = 10\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, timeout=(60*minutes))\n",
    "results = study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337.0709845015816,\n",
       " 332.2849758381657,\n",
       " 18.35949303498279,\n",
       " {'alpha': 0.005431704895799771,\n",
       "  'colsample_bytree': 0.7063898876659078,\n",
       "  'eta': 0.08220319061595308,\n",
       "  'max_depth': 10,\n",
       "  'min_child_weight': 58,\n",
       "  'subsample': 0.9724863280502848})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_best = results.value.idxmin()\n",
    "param_cols = [x for x in results.columns if x.startswith('params_')]\n",
    "best_params = results.loc[idx_best, param_cols]\n",
    "best_params.index = [x.replace('params_','') for x in best_params.index]\n",
    "params = best_params.to_dict()\n",
    "\n",
    "xgb_pipe = Pipeline(\n",
    "        steps = [\n",
    "            ('feature_clipper', Windsorizer()),\n",
    "            ('normalizer', PowerTransformer()),\n",
    "            ('xgb', XGBRegressor(**params)),\n",
    "        ])\n",
    "\n",
    "xgb_pipe.fit(X_train,y_train)\n",
    "preds = xgb_pipe.predict(X_test)\n",
    "mse = mean_squared_error(y_true=np.exp(y_test), y_pred=np.exp(preds))\n",
    "mse_train = mean_squared_error(y_true=np.exp(y_train), y_pred=np.exp(xgb_pipe.predict(X_train)))\n",
    "mse , mse_train, np.sqrt(mse), params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>previousMarketCap</th>\n",
       "      <td>0.36454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>0.13058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalAssets</th>\n",
       "      <td>0.07059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdaToRevenue</th>\n",
       "      <td>0.04531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netIncomeToRevenue</th>\n",
       "      <td>0.02819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operatingIncomeToRevenue</th>\n",
       "      <td>0.02491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>researchAndDevelopmentExpensesToRevenue</th>\n",
       "      <td>0.02477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchasesOfInvestmentsToRevenue</th>\n",
       "      <td>0.01935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPEtoSales</th>\n",
       "      <td>0.01807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retainedEarningsToAssets</th>\n",
       "      <td>0.01783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netDebtToAssets</th>\n",
       "      <td>0.01318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferredRevenueToAssets</th>\n",
       "      <td>0.01231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stockBasedCompensationToRevenue</th>\n",
       "      <td>0.01173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netDebtToEBITDA</th>\n",
       "      <td>0.01103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sellingGeneralAndAdministrativeExpensesToRevenue</th>\n",
       "      <td>0.01007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalStockholdersEquityToAssets</th>\n",
       "      <td>0.00993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeCashFlowToRevenue</th>\n",
       "      <td>0.00795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roe</th>\n",
       "      <td>0.00747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>changeInWorkingCapitalToRevenueYearOverYear</th>\n",
       "      <td>0.00726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propertyPlantEquipmentNetToAssets</th>\n",
       "      <td>0.00622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cashAndCashEquivalentsToAssets</th>\n",
       "      <td>0.00618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intangibleAssetsToAssets</th>\n",
       "      <td>0.00603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capitalExpenditureToRevenue</th>\n",
       "      <td>0.00590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>changeInWorkingCapitalToRevenue</th>\n",
       "      <td>0.00565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortTermDebtToAssets</th>\n",
       "      <td>0.00551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>otherCurrentAssetsToAssets</th>\n",
       "      <td>0.00522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costOfRevenueToRevenue</th>\n",
       "      <td>0.00490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdaToRevenueYearOverYear</th>\n",
       "      <td>0.00485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortTermInvestmentsToAssets</th>\n",
       "      <td>0.00475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longTermDebtToAssets</th>\n",
       "      <td>0.00474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenueYoY</th>\n",
       "      <td>0.00447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accountPayablesToAssets</th>\n",
       "      <td>0.00439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inventoryToAssets</th>\n",
       "      <td>0.00428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeCashFlowGivenToShareholders</th>\n",
       "      <td>0.00424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>otherNonCurrentLiabilitiesToAssets</th>\n",
       "      <td>0.00421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depreciationAndAmortizationToRevenue</th>\n",
       "      <td>0.00415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdaToRevenueYearOverYearSMA3</th>\n",
       "      <td>0.00404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dividendsPaidToRevenue</th>\n",
       "      <td>0.00394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>otherCurrentLiabilitiesToAssets</th>\n",
       "      <td>0.00392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeCashFlowToRevenueYearOverYear</th>\n",
       "      <td>0.00382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netSharesRepurchasedToRevenue</th>\n",
       "      <td>0.00379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenueYoYSMA3</th>\n",
       "      <td>0.00364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costOfRevenueToRevenueYearOverYearSMA3</th>\n",
       "      <td>0.00356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>otherNonCurrentAssetsToAssets</th>\n",
       "      <td>0.00351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longTermInvestmentsToAssets</th>\n",
       "      <td>0.00332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netIncomeToRevenueYearOverYear</th>\n",
       "      <td>0.00313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>costOfRevenueToRevenueYearOverYear</th>\n",
       "      <td>0.00309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capitalExpenditureToRevenueYearOverYear</th>\n",
       "      <td>0.00294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sellingGeneralAndAdministrativeExpensesToRevenueYearOverYearSMA3</th>\n",
       "      <td>0.00292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquisitionsNetToRevenueYearOverYear</th>\n",
       "      <td>0.00290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operatingIncomeToRevenueYearOverYearSMA3</th>\n",
       "      <td>0.00289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netIncomeToRevenueYearOverYearSMA3</th>\n",
       "      <td>0.00279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>researchAndDevelopmentExpensesToRevenueYearOverYear</th>\n",
       "      <td>0.00276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquisitionsNetToRevenue</th>\n",
       "      <td>0.00275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operatingIncomeToRevenueYearOverYear</th>\n",
       "      <td>0.00274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depreciationAndAmortizationToRevenueYearOverYear</th>\n",
       "      <td>0.00270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sellingGeneralAndAdministrativeExpensesToRevenueYearOverYear</th>\n",
       "      <td>0.00266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netReceivablesToAssets</th>\n",
       "      <td>0.00266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dividendsPaidToRevenueYearOverYear</th>\n",
       "      <td>0.00231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>researchAndDevelopmentExpensesToRevenueYearOverYearSMA3</th>\n",
       "      <td>0.00224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stockBasedCompensationToRevenueYearOverYear</th>\n",
       "      <td>0.00214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchasesOfInvestmentsToRevenueYearOverYear</th>\n",
       "      <td>0.00203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    importances\n",
       "previousMarketCap                                       0.36454\n",
       "revenue                                                 0.13058\n",
       "totalAssets                                             0.07059\n",
       "ebitdaToRevenue                                         0.04531\n",
       "netIncomeToRevenue                                      0.02819\n",
       "operatingIncomeToRevenue                                0.02491\n",
       "researchAndDevelopmentExpensesToRevenue                 0.02477\n",
       "purchasesOfInvestmentsToRevenue                         0.01935\n",
       "PPEtoSales                                              0.01807\n",
       "retainedEarningsToAssets                                0.01783\n",
       "netDebtToAssets                                         0.01318\n",
       "deferredRevenueToAssets                                 0.01231\n",
       "stockBasedCompensationToRevenue                         0.01173\n",
       "netDebtToEBITDA                                         0.01103\n",
       "sellingGeneralAndAdministrativeExpensesToRevenue        0.01007\n",
       "totalStockholdersEquityToAssets                         0.00993\n",
       "freeCashFlowToRevenue                                   0.00795\n",
       "roe                                                     0.00747\n",
       "changeInWorkingCapitalToRevenueYearOverYear             0.00726\n",
       "propertyPlantEquipmentNetToAssets                       0.00622\n",
       "cashAndCashEquivalentsToAssets                          0.00618\n",
       "intangibleAssetsToAssets                                0.00603\n",
       "capitalExpenditureToRevenue                             0.00590\n",
       "changeInWorkingCapitalToRevenue                         0.00565\n",
       "shortTermDebtToAssets                                   0.00551\n",
       "otherCurrentAssetsToAssets                              0.00522\n",
       "costOfRevenueToRevenue                                  0.00490\n",
       "ebitdaToRevenueYearOverYear                             0.00485\n",
       "shortTermInvestmentsToAssets                            0.00475\n",
       "longTermDebtToAssets                                    0.00474\n",
       "revenueYoY                                              0.00447\n",
       "accountPayablesToAssets                                 0.00439\n",
       "inventoryToAssets                                       0.00428\n",
       "freeCashFlowGivenToShareholders                         0.00424\n",
       "otherNonCurrentLiabilitiesToAssets                      0.00421\n",
       "depreciationAndAmortizationToRevenue                    0.00415\n",
       "ebitdaToRevenueYearOverYearSMA3                         0.00404\n",
       "dividendsPaidToRevenue                                  0.00394\n",
       "otherCurrentLiabilitiesToAssets                         0.00392\n",
       "freeCashFlowToRevenueYearOverYear                       0.00382\n",
       "netSharesRepurchasedToRevenue                           0.00379\n",
       "revenueYoYSMA3                                          0.00364\n",
       "costOfRevenueToRevenueYearOverYearSMA3                  0.00356\n",
       "otherNonCurrentAssetsToAssets                           0.00351\n",
       "longTermInvestmentsToAssets                             0.00332\n",
       "netIncomeToRevenueYearOverYear                          0.00313\n",
       "costOfRevenueToRevenueYearOverYear                      0.00309\n",
       "capitalExpenditureToRevenueYearOverYear                 0.00294\n",
       "sellingGeneralAndAdministrativeExpensesToRevenu...      0.00292\n",
       "acquisitionsNetToRevenueYearOverYear                    0.00290\n",
       "operatingIncomeToRevenueYearOverYearSMA3                0.00289\n",
       "netIncomeToRevenueYearOverYearSMA3                      0.00279\n",
       "researchAndDevelopmentExpensesToRevenueYearOver...      0.00276\n",
       "acquisitionsNetToRevenue                                0.00275\n",
       "operatingIncomeToRevenueYearOverYear                    0.00274\n",
       "depreciationAndAmortizationToRevenueYearOverYear        0.00270\n",
       "sellingGeneralAndAdministrativeExpensesToRevenu...      0.00266\n",
       "netReceivablesToAssets                                  0.00266\n",
       "dividendsPaidToRevenueYearOverYear                      0.00231\n",
       "researchAndDevelopmentExpensesToRevenueYearOver...      0.00224\n",
       "stockBasedCompensationToRevenueYearOverYear             0.00214\n",
       "purchasesOfInvestmentsToRevenueYearOverYear             0.00203"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict(zip(X_train.columns, xgb_pipe['xgb'].feature_importances_)),index=['importances']).T.sort_values(by='importances', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['totalAssets', 'revenue', 'revenueYoY', 'revenueYoYSMA3',\n",
       "       'previousMarketCap', 'cashAndCashEquivalentsToAssets',\n",
       "       'shortTermInvestmentsToAssets', 'netReceivablesToAssets',\n",
       "       'inventoryToAssets', 'otherCurrentAssetsToAssets',\n",
       "       'propertyPlantEquipmentNetToAssets', 'intangibleAssetsToAssets',\n",
       "       'longTermInvestmentsToAssets', 'otherNonCurrentAssetsToAssets',\n",
       "       'accountPayablesToAssets', 'shortTermDebtToAssets',\n",
       "       'deferredRevenueToAssets', 'otherCurrentLiabilitiesToAssets',\n",
       "       'longTermDebtToAssets', 'otherNonCurrentLiabilitiesToAssets',\n",
       "       'retainedEarningsToAssets', 'totalStockholdersEquityToAssets',\n",
       "       'netDebtToAssets', 'costOfRevenueToRevenue',\n",
       "       'researchAndDevelopmentExpensesToRevenue',\n",
       "       'sellingGeneralAndAdministrativeExpensesToRevenue', 'ebitdaToRevenue',\n",
       "       'operatingIncomeToRevenue', 'netIncomeToRevenue',\n",
       "       'costOfRevenueToRevenueYearOverYear',\n",
       "       'researchAndDevelopmentExpensesToRevenueYearOverYear',\n",
       "       'sellingGeneralAndAdministrativeExpensesToRevenueYearOverYear',\n",
       "       'ebitdaToRevenueYearOverYear', 'operatingIncomeToRevenueYearOverYear',\n",
       "       'netIncomeToRevenueYearOverYear',\n",
       "       'costOfRevenueToRevenueYearOverYearSMA3',\n",
       "       'researchAndDevelopmentExpensesToRevenueYearOverYearSMA3',\n",
       "       'sellingGeneralAndAdministrativeExpensesToRevenueYearOverYearSMA3',\n",
       "       'ebitdaToRevenueYearOverYearSMA3',\n",
       "       'operatingIncomeToRevenueYearOverYearSMA3',\n",
       "       'netIncomeToRevenueYearOverYearSMA3', 'stockBasedCompensationToRevenue',\n",
       "       'depreciationAndAmortizationToRevenue',\n",
       "       'changeInWorkingCapitalToRevenue', 'freeCashFlowToRevenue',\n",
       "       'capitalExpenditureToRevenue', 'acquisitionsNetToRevenue',\n",
       "       'purchasesOfInvestmentsToRevenue', 'dividendsPaidToRevenue',\n",
       "       'netSharesRepurchasedToRevenue',\n",
       "       'stockBasedCompensationToRevenueYearOverYear',\n",
       "       'depreciationAndAmortizationToRevenueYearOverYear',\n",
       "       'changeInWorkingCapitalToRevenueYearOverYear',\n",
       "       'freeCashFlowToRevenueYearOverYear',\n",
       "       'capitalExpenditureToRevenueYearOverYear',\n",
       "       'acquisitionsNetToRevenueYearOverYear',\n",
       "       'purchasesOfInvestmentsToRevenueYearOverYear',\n",
       "       'dividendsPaidToRevenueYearOverYear', 'freeCashFlowGivenToShareholders',\n",
       "       'PPEtoSales', 'netDebtToEBITDA', 'roe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/my_model.pickle', 'rb') as f:\n",
    "    xgb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/test2.csv')\n",
    "features = data.drop(columns=['target'])\n",
    "target = data.target\n",
    "preds = xgb.predict(features)\n",
    "mse = mean_squared_error(y_true=np.exp(target), y_pred=np.exp(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v2\n",
    "- clipping the the previousMarketCap feature destroys outliers. \n",
    "  - Filter clipping by kurtosis\n",
    "  - Predict Increases\n",
    "- Try to simulate a neural network with different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1af52d91e9a17fda2c5a861893e28b9d34197fc091af0d7ff917999a49fdd885"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
